# -*- coding: utf-8 -*-
"""Model 3105 vGit

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e0E3CNxeZtci0qNUqPvFhj5V6-B2wlBe
"""

gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Not connected to a GPU')
else:
  print(gpu_info)

"""**Initialization**


1.   langchain_community
2.   pandas
3.   json
4.   os
5.   sys

"""

pip install langchain_community

pip install -U langchain langchain-openai

pip install fasttext

!pip install snorkel

from langchain.output_parsers import StructuredOutputParser, ResponseSchema
from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate
from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI
from langchain.tools import tool
from langchain.agents import initialize_agent, AgentType
from langchain.memory import ConversationBufferMemory
from langchain.chains import SequentialChain

import pandas as pd
import numpy as np
import json
import sys
import os
import random

"""

---

**FASTEXT INITIAL SETUP**"""

import fasttext
import fasttext.util
import os

# Path to save the model
model_path = 'cc.fr.300.bin'
compressed_model_path = 'cc.fr.300.bin.gz'

# Check if the model already exists
if not os.path.isfile(model_path):
    # If it doesn't exist, download the compressed version
    if not os.path.isfile(compressed_model_path):
        fasttext.util.download_model('fr', if_exists='ignore')  # This downloads the compressed .bin.gz file

# Load the model
ft = fasttext.load_model(model_path)

# Optionally, you can reduce the dimensions to make it even lighter
# This significantly reduces memory usage
reduced_dim = 100  # You can choose 100 or even lower like 50
fasttext.util.reduce_model(ft, reduced_dim)

import fasttext
import fasttext.util
import os

# Define the path where the model is stored
MODEL_PATH = "cc.fr.300.bin"  # Change this to the correct location if needed

# Load the FastText model if it exists
if os.path.exists(MODEL_PATH):
    ft = fasttext.load_model(MODEL_PATH)
    print("FastText model loaded successfully from local file.")
else:
    print(f"Error: Model file '{MODEL_PATH}' not found. Please check the path.")
    exit()

## AI MODEL ##
llm = ChatOpenAI(model_name="gpt-4-turbo",temperature=0)

Step4_xls = pd.read_excel(f"Step4_xls.xlsx")

# 0) Starting from your raw df with columns:
#    ACCOUNT_ID, CLEANED_TEXT, AMOUNT, DATE, NAF_CODE, MERCHANT, …

# 1) Parse dates
Step4_xls["DATE"] = pd.to_datetime(Step4_xls["DATE"], dayfirst=True)

# 2) Group by account & cleaned text, but keep the mode NAF_CODE
grouped = Step4_xls.groupby(["CLEANED_TEXT"])

Step4_xls["AMOUNT"] = (
    Step4_xls["AMOUNT"]
    .str.replace(r"\s+", "", regex=True)    # remove any spaces
    .str.replace(r"\.", "", regex=True)     # remove any dots used as thousand sep
    .str.replace(",", ".", regex=False)     # convert decimal comma to point
    .astype(float)                          # cast to float
)

agg_df = grouped.agg(
    # Numeric time‐series stats
    amt_count       = ("AMOUNT", "count"),
    amt_sum         = ("AMOUNT", "sum"),
    amt_mean        = ("AMOUNT", "mean"),
    amt_std         = ("AMOUNT", "std"),
    amt_median      = ("AMOUNT", "median"),
    amt_min         = ("AMOUNT", "min"),
    amt_max         = ("AMOUNT", "max"),
    amt_cv          = ("AMOUNT", lambda x: x.std()/x.mean() if x.mean() else 0),
    mean_delta_days = ("DATE", lambda x: np.diff(np.sort(x)).astype("timedelta64[D]").astype(int).mean()
                                             if len(x)>1 else 0),
    # Carry forward a single NAF_CODE per group
    NAF_CODE        = ("NAF_CODE", lambda x: x.mode().iat[0] if not x.mode().empty else None),
    # Keep one representative merchant if needed
    MERCHANT        = ("MERCHANT", lambda x: x.mode().iat[0] if not x.mode().empty else ""),
).reset_index()

agg_df["group_id"] = np.arange(len(agg_df))

agg_df.head()

agg_df.to_excel("ParseDatacCLEANEDTEXT_xls.xlsx", sheet_name="MySheet", index=False)

# Group by MERCHANT this time
merchant_grouped = Step4_xls.groupby(["MERCHANT"])

# Perform aggregation, keeping the mode of CLEANED_TEXT
merchant_agg_df = merchant_grouped.agg(
    # Keep the same numeric aggregations as before
    amt_count       = ("AMOUNT", "count"),
    amt_sum         = ("AMOUNT", "sum"),
    amt_mean        = ("AMOUNT", "mean"),
    amt_std         = ("AMOUNT", "std"),
    amt_median      = ("AMOUNT", "median"),
    amt_min         = ("AMOUNT", "min"),
    amt_max         = ("AMOUNT", "max"),
    amt_cv          = ("AMOUNT", lambda x: x.std()/x.mean() if x.mean() else 0),
    mean_delta_days = ("DATE", lambda x: np.diff(np.sort(x)).astype("timedelta64[D]").astype(int).mean()
                                      if len(x)>1 else 0),

    # Keep one representative CLEANED_TEXT per merchant group
    CLEANED_TEXT    = ("CLEANED_TEXT", lambda x: x.mode().iat[0] if not x.mode().empty else ""),

    # You might also want to keep the mode NAF_CODE as before
    NAF_CODE        = ("NAF_CODE", lambda x: x.mode().iat[0] if not x.mode().empty else None),
).reset_index()

merchant_agg_df["merchant_group_id"] = np.arange(len(merchant_agg_df))

merchant_agg_df.to_excel("ParseDatacMERCHANT_xls.xlsx", sheet_name="MySheet", index=False)

merchant_agg_df.head()

"""---

# Salary
"""

#5# THIRD APPROACH FOR SIMULTANEOUS INCOME STREAM POSSIBILITY

"""
Complete Multi-Income Classification System
Single file version for Google Colab
"""

import numpy as np
import pandas as pd
from snorkel.labeling import LabelingFunction, PandasLFApplier
from snorkel.labeling.model import LabelModel
from snorkel.labeling import LFAnalysis
from dataclasses import dataclass
from typing import Optional, Dict, List, Set
from enum import Enum

# ===========================
# CONSTANTS AND ENUMS
# ===========================

# Binary labels for classification
POSITIVE = 1
NEGATIVE = 0
ABSTAIN = -1

class IncomeSource(Enum):
    FULL_TIME = "full_time"
    PART_TIME = "part_time"
    FREELANCE = "freelance"
    SELF_EMPLOYED = "self_employed"
    RETIRED = "retired"

class PaymentFrequency(Enum):
    WEEKLY = "weekly"
    BIWEEKLY = "biweekly"
    MONTHLY = "monthly"
    IRREGULAR = "irregular"

# ===========================
# USER PROFILE CLASS
# ===========================

@dataclass
class UserProfile:
    income_sources: Set[IncomeSource]  # Multiple income sources
    monthly_income_range: str  # "under_1500", "1500_4000", "4000_plus"
    primary_income_source: Optional[IncomeSource] = None  # Main income source
    payment_frequencies: Optional[Dict[IncomeSource, PaymentFrequency]] = None

    def __post_init__(self):
        """Determine which classifiers to use and calculate thresholds"""
        self.needs_salary_classifier = any(source in [IncomeSource.FULL_TIME, IncomeSource.PART_TIME]
                                         for source in self.income_sources)
        self.needs_work_income_classifier = any(source in [IncomeSource.FREELANCE, IncomeSource.SELF_EMPLOYED]
                                              for source in self.income_sources)
        self.needs_pension_classifier = IncomeSource.RETIRED in self.income_sources

        # Set primary if not specified
        if not self.primary_income_source and self.income_sources:
            self.primary_income_source = next(iter(self.income_sources))

        # Initialize payment frequencies if not provided
        if not self.payment_frequencies:
            self.payment_frequencies = {}

        # Calculate thresholds for each needed classifier
        self.salary_thresholds = self._calculate_salary_thresholds() if self.needs_salary_classifier else {}
        self.work_income_thresholds = self._calculate_work_income_thresholds() if self.needs_work_income_classifier else {}
        self.pension_thresholds = self._calculate_pension_thresholds() if self.needs_pension_classifier else {}

    def get_active_classifiers(self) -> List[str]:
        """Return list of classifiers that should be run"""
        classifiers = []
        if self.needs_salary_classifier:
            classifiers.append("salary")
        if self.needs_work_income_classifier:
            classifiers.append("work_income")
        if self.needs_pension_classifier:
            classifiers.append("pension")
        return classifiers

    def _calculate_salary_thresholds(self) -> Dict[str, float]:
        """Calculate thresholds specifically for salary detection (EUR)"""
        if not self.needs_salary_classifier:
            return {}

        # Check what type of employment for salary
        has_full_time = IncomeSource.FULL_TIME in self.income_sources
        has_part_time = IncomeSource.PART_TIME in self.income_sources

        base_thresholds = {
            'weekly_min': 150,      # ~€600/month minimum
            'biweekly_min': 300,    # ~€600/month minimum
            'monthly_min': 600,     # €600/month minimum
            'max_cv': 0.2           # Lower CV for salary (more consistent)
        }

        # Adjust based on full-time vs part-time (prioritize full-time if both)
        if has_full_time:
            base_thresholds.update({
                'weekly_min': 250,     # ~€1000/month
                'biweekly_min': 500,   # ~€1000/month
                'monthly_min': 1000,   # €1000/month
                'max_cv': 0.15         # Very consistent for full-time
            })
        elif has_part_time:
            base_thresholds.update({
                'weekly_min': 120,     # ~€480/month
                'biweekly_min': 240,   # ~€480/month
                'monthly_min': 480,    # €480/month
                'max_cv': 0.25         # Slightly more variable
            })

        # Adjust based on income range
        self._adjust_thresholds_by_income(base_thresholds)

        return base_thresholds

    def _calculate_work_income_thresholds(self) -> Dict[str, float]:
        """Calculate thresholds specifically for work income detection (EUR)"""
        if not self.needs_work_income_classifier:
            return {}

        # Check what type of work income
        has_freelance = IncomeSource.FREELANCE in self.income_sources
        has_self_employed = IncomeSource.SELF_EMPLOYED in self.income_sources
        is_primary_work_income = self.primary_income_source in [IncomeSource.FREELANCE, IncomeSource.SELF_EMPLOYED]

        base_thresholds = {
            'minimum_amount': 200,   # Minimum per transaction
            'monthly_equivalent': 500,  # Minimum monthly equivalent
            'max_cv': 0.6,          # Much higher CV tolerance
            'min_transactions': 2    # Minimum number of transactions
        }

        # If it's primary income, use higher thresholds
        if is_primary_work_income:
            if has_freelance:
                base_thresholds.update({
                    'minimum_amount': 300,     # Projects tend to be larger
                    'monthly_equivalent': 800,
                    'max_cv': 0.7              # Very variable project income
                })
            elif has_self_employed:
                base_thresholds.update({
                    'minimum_amount': 250,     # Business income
                    'monthly_equivalent': 600,
                    'max_cv': 0.6              # Somewhat more regular than freelance
                })
        else:
            # Side hustle - lower thresholds
            base_thresholds.update({
                'minimum_amount': 100,     # Side projects can be smaller
                'monthly_equivalent': 200,  # Lower monthly equivalent for side income
                'max_cv': 0.8              # Very flexible for side income
            })

        # Adjust based on income range
        self._adjust_thresholds_by_income(base_thresholds)

        return base_thresholds

    def _calculate_pension_thresholds(self) -> Dict[str, float]:
        """Calculate thresholds specifically for pension detection (EUR)"""
        if not self.needs_pension_classifier:
            return {}

        is_primary_pension = self.primary_income_source == IncomeSource.RETIRED

        base_thresholds = {
            'monthly_min': 300,     # Minimum pension amount
            'monthly_max': 3000,    # Maximum reasonable pension
            'max_cv': 0.05,         # Very low variability (pensions are very consistent)
            'frequency_tolerance': 2  # Days tolerance for monthly payments (28-32 days)
        }

        # If pension is not primary (i.e., has other income), might be smaller pension
        if not is_primary_pension:
            base_thresholds.update({
                'monthly_min': 200,     # Smaller pensions possible
                'max_cv': 0.1           # Slightly more flexible
            })

        # Adjust based on income range
        if self.monthly_income_range == "under_1500":
            base_thresholds.update({
                'monthly_min': 200,
                'monthly_max': 1500
            })
        elif self.monthly_income_range == "1500_4000":
            base_thresholds.update({
                'monthly_min': 300 if is_primary_pension else 200,
                'monthly_max': 4000
            })
        elif self.monthly_income_range == "4000_plus":
            base_thresholds.update({
                'monthly_min': 500 if is_primary_pension else 300,
                'monthly_max': 6000
            })

        return base_thresholds

    def _adjust_thresholds_by_income(self, thresholds: Dict[str, float]):
        """Apply income range adjustments to thresholds"""
        if self.monthly_income_range == "under_1500":
            for key in thresholds:
                if 'min' in key or 'amount' in key or 'equivalent' in key:
                    thresholds[key] *= 0.7
        elif self.monthly_income_range == "4000_plus":
            for key in thresholds:
                if 'min' in key or 'amount' in key or 'equivalent' in key:
                    thresholds[key] *= 1.4

# ===========================
# DETECTOR CLASSES
# ===========================

class SalaryDetector:
    """Detector specifically for traditional salary (full-time/part-time employees)"""

    def __init__(self, user_profile: UserProfile):
        self.user_profile = user_profile
        self.thresholds = user_profile.salary_thresholds
        self.salary_anchors = [
            "salaire", "paie", "remuneration", "salary", "wages", "payroll",
            "employeur", "entreprise", "virement", "direct deposit", "dd",
            "net pay", "gross pay", "mensuel", "hebdomadaire"
        ]

    def create_salary_labeling_functions(self):
        """Create labeling functions for salary detection"""

        def lf_salary_regular_payments(x):
            """Detect regular salary payments with consistent amounts"""
            if x.amt_mean <= 0 or x.amt_count < 2:
                return ABSTAIN

            # Check for regular payment patterns
            is_weekly = 6 <= x.mean_delta_days <= 8
            is_biweekly = 13 <= x.mean_delta_days <= 16
            is_monthly = 26 <= x.mean_delta_days <= 32

            # Must be consistent (low variability)
            is_consistent = x.amt_cv < self.thresholds['max_cv']

            if not is_consistent:
                return ABSTAIN

            # Check amount thresholds by frequency
            if is_weekly and x.amt_mean >= self.thresholds['weekly_min']:
                return POSITIVE
            elif is_biweekly and x.amt_mean >= self.thresholds['biweekly_min']:
                return POSITIVE
            elif is_monthly and x.amt_mean >= self.thresholds['monthly_min']:
                return POSITIVE

            return ABSTAIN

        def lf_salary_text_indicators(x):
            """Detect salary based on text indicators"""
            if pd.isna(x.CLEANED_TEXT) or x.CLEANED_TEXT == "":
                return ABSTAIN

            text_lower = x.CLEANED_TEXT.lower()

            # Strong salary indicators
            if any(anchor in text_lower for anchor in self.salary_anchors):
                if x.amt_mean >= self.thresholds['monthly_min'] * 0.5:  # Lower threshold with text confirmation
                    return POSITIVE

            return ABSTAIN

        def lf_salary_expected_frequency(x):
            """Use user's stated payment frequency for salary detection"""
            if not self.user_profile.payment_frequencies or x.amt_mean <= 0:
                return ABSTAIN

            # Check if any employment source has a stated frequency
            relevant_sources = [source for source in self.user_profile.income_sources
                              if source in [IncomeSource.FULL_TIME, IncomeSource.PART_TIME]]

            if not relevant_sources:
                return ABSTAIN

            # Check frequencies for relevant sources
            for source in relevant_sources:
                if source in self.user_profile.payment_frequencies:
                    freq = self.user_profile.payment_frequencies[source]

                    # Must match user's stated frequency and be consistent
                    if freq == PaymentFrequency.WEEKLY and 6 <= x.mean_delta_days <= 8:
                        if x.amt_mean >= self.thresholds['weekly_min'] and x.amt_cv < 0.2:
                            return POSITIVE
                    elif freq == PaymentFrequency.BIWEEKLY and 13 <= x.mean_delta_days <= 16:
                        if x.amt_mean >= self.thresholds['biweekly_min'] and x.amt_cv < 0.2:
                            return POSITIVE
                    elif freq == PaymentFrequency.MONTHLY and 26 <= x.mean_delta_days <= 32:
                        if x.amt_mean >= self.thresholds['monthly_min'] and x.amt_cv < 0.2:
                            return POSITIVE

            return ABSTAIN

        def lf_not_salary_irregular(x):
            """Negative LF: Highly irregular payments are not salary"""
            if x.amt_cv > 0.5 or x.amt_count == 1:
                return NEGATIVE
            return ABSTAIN

        def lf_not_salary_very_small(x):
            """Negative LF: Very small amounts are not salary"""
            if x.amt_mean < 100:  # Less than €100 is unlikely to be salary
                return NEGATIVE
            return ABSTAIN

        return [
            LabelingFunction(name="lf_salary_regular_payments", f=lf_salary_regular_payments),
            LabelingFunction(name="lf_salary_text_indicators", f=lf_salary_text_indicators),
            LabelingFunction(name="lf_salary_expected_frequency", f=lf_salary_expected_frequency),
            LabelingFunction(name="lf_not_salary_irregular", f=lf_not_salary_irregular),
            LabelingFunction(name="lf_not_salary_very_small", f=lf_not_salary_very_small),
        ]

class WorkIncomeDetector:
    """Detector specifically for freelance/self-employed work income"""

    def __init__(self, user_profile: UserProfile):
        self.user_profile = user_profile
        self.thresholds = user_profile.work_income_thresholds
        self.work_income_anchors = [
            "facture", "invoice", "freelance", "consulting", "honoraires",
            "prestation", "service", "project", "client", "contrat",
            "independent", "contractor", "self employed", "business",
            "payment", "fees", "commission"
        ]

    def create_work_income_labeling_functions(self):
        """Create labeling functions for work income detection"""

        def lf_work_income_amount_threshold(x):
            """Detect work income based on amount patterns"""
            if x.amt_mean <= 0 or x.amt_count < self.thresholds['min_transactions']:
                return ABSTAIN

            # Check if amounts are reasonable for work income
            if x.amt_mean >= self.thresholds['minimum_amount']:
                # Allow higher variability than salary
                if x.amt_cv <= self.thresholds['max_cv']:
                    return POSITIVE

            return ABSTAIN

        def lf_work_income_text_indicators(x):
            """Detect work income based on text indicators"""
            if pd.isna(x.CLEANED_TEXT) or x.CLEANED_TEXT == "":
                return ABSTAIN

            text_lower = x.CLEANED_TEXT.lower()

            # Strong work income indicators
            if any(anchor in text_lower for anchor in self.work_income_anchors):
                if x.amt_mean >= self.thresholds['minimum_amount'] * 0.5:  # Lower threshold with text confirmation
                    return POSITIVE

            return ABSTAIN

        def lf_work_income_monthly_equivalent(x):
            """Check if irregular payments meet monthly equivalent threshold"""
            if x.amt_mean <= 0 or x.amt_count < 2:
                return ABSTAIN

            # Calculate approximate monthly equivalent based on frequency
            if x.mean_delta_days > 0:
                monthly_equivalent = (x.amt_mean * 30) / x.mean_delta_days
                if monthly_equivalent >= self.thresholds['monthly_equivalent']:
                    return POSITIVE

            return ABSTAIN

        def lf_work_income_project_patterns(x):
            """Detect project-based income patterns"""
            if x.amt_mean <= 0:
                return ABSTAIN

            # Freelance/project work often has:
            # - Larger amounts (€500+)
            # - Less frequent but substantial payments
            # - Moderate variability

            if (x.amt_mean >= 500 and
                x.amt_cv >= 0.2 and x.amt_cv <= 0.8 and  # Some variability expected
                x.amt_count >= 2):
                return POSITIVE

            return ABSTAIN

        def lf_not_work_income_too_regular(x):
            """Negative LF: Very regular payments might be salary, not freelance income"""
            # If payments are very regular AND consistent, might be salary instead
            is_very_regular = (26 <= x.mean_delta_days <= 32 or
                             13 <= x.mean_delta_days <= 16 or
                             6 <= x.mean_delta_days <= 8)
            is_very_consistent = x.amt_cv < 0.1

            if is_very_regular and is_very_consistent:
                return NEGATIVE

            return ABSTAIN

        def lf_not_work_income_too_small(x):
            """Negative LF: Very small amounts unlikely to be professional work income"""
            if x.amt_mean < 50:  # Less than €50 is unlikely to be professional work
                return NEGATIVE
            return ABSTAIN

        return [
            LabelingFunction(name="lf_work_income_amount_threshold", f=lf_work_income_amount_threshold),
            LabelingFunction(name="lf_work_income_text_indicators", f=lf_work_income_text_indicators),
            LabelingFunction(name="lf_work_income_monthly_equivalent", f=lf_work_income_monthly_equivalent),
            LabelingFunction(name="lf_work_income_project_patterns", f=lf_work_income_project_patterns),
            LabelingFunction(name="lf_not_work_income_too_regular", f=lf_not_work_income_too_regular),
            LabelingFunction(name="lf_not_work_income_too_small", f=lf_not_work_income_too_small),
        ]

class PensionDetector:
    """Detector specifically for pension/retirement income"""

    def __init__(self, user_profile: UserProfile):
        self.user_profile = user_profile
        self.thresholds = user_profile.pension_thresholds
        self.pension_anchors = [
            "pension", "retraite", "retirement", "pensionskasse", "rente",
            "social security", "securite sociale", "agirc", "arrco",
            "complementaire", "cnav", "carsat", "msa", "cipav",
            "malakoff", "ag2r", "klesia", "pro btp", "ircantec",
            "pension fund", "retirement fund", "annuity", "survivor"
        ]

    def create_pension_labeling_functions(self):
        """Create labeling functions for pension detection"""

        def lf_pension_regular_monthly(x):
            """Detect regular monthly pension payments"""
            if x.amt_mean <= 0 or x.amt_count < 2:
                return ABSTAIN

            # More flexible monthly pattern (24-35 days)
            is_monthly = 24 <= x.mean_delta_days <= 35

            # More flexible consistency (pensions can have small variations)
            is_consistent = x.amt_cv <= 0.15  # Increased from 0.05

            # More flexible pension range
            in_pension_range = x.amt_mean >= 200  # Just minimum check

            if is_monthly and is_consistent and in_pension_range:
                return POSITIVE

            return ABSTAIN

        def lf_pension_text_indicators(x):
            """Detect pension based on text indicators"""
            if pd.isna(x.CLEANED_TEXT) or x.CLEANED_TEXT == "":
                return ABSTAIN

            text_lower = x.CLEANED_TEXT.lower()

            # Strong pension indicators
            if any(anchor in text_lower for anchor in self.pension_anchors):
                # Lower amount threshold when we have strong text confirmation
                if x.amt_mean >= self.thresholds['monthly_min'] * 0.5:
                    return POSITIVE

            return ABSTAIN

        def lf_pension_ultra_consistent(x):
            """Detect ultra-consistent payments typical of pensions"""
            if x.amt_mean <= 0 or x.amt_count < 2:  # Reduced from 3 to 2
                return ABSTAIN

            # More flexible consistency threshold
            is_consistent = x.amt_cv <= 0.1  # Increased from 0.02
            is_reasonable_amount = x.amt_mean >= 150  # Reduced threshold
            is_monthly_ish = 20 <= x.mean_delta_days <= 40  # More flexible range

            if is_consistent and is_reasonable_amount and is_monthly_ish:
                return POSITIVE

            return ABSTAIN

        def lf_pension_expected_range(x):
            """Check if payment matches user's expected pension range"""
            if x.amt_mean <= 0:
                return ABSTAIN

            # More flexible thresholds
            min_threshold = max(150, self.thresholds['monthly_min'] * 0.5)  # At least €150
            max_threshold = self.thresholds['monthly_max'] * 1.5  # More flexible upper bound

            in_range = min_threshold <= x.amt_mean <= max_threshold
            is_consistent = x.amt_cv <= 0.2  # More flexible consistency
            is_regular = 20 <= x.mean_delta_days <= 40  # Broader monthly range

            if in_range and is_consistent and is_regular:
                return POSITIVE

            return ABSTAIN

        def lf_not_pension_too_variable(x):
            """Negative LF: Variable amounts are not pensions"""
            if x.amt_cv > 0.15:  # More than 15% variation unlikely for pension
                return NEGATIVE
            return ABSTAIN

        def lf_not_pension_wrong_frequency(x):
            """Negative LF: Non-monthly patterns are not typical pensions"""
            # Weekly or bi-weekly patterns are not typical for pensions
            is_weekly = 6 <= x.mean_delta_days <= 8
            is_biweekly = 13 <= x.mean_delta_days <= 16

            if is_weekly or is_biweekly:
                return NEGATIVE

            return ABSTAIN

        def lf_not_pension_too_high(x):
            """Negative LF: Extremely high amounts unlikely to be standard pension"""
            if x.amt_mean > 5000:  # Very high amounts might be other income
                return NEGATIVE
            return ABSTAIN

        return [
            LabelingFunction(name="lf_pension_regular_monthly", f=lf_pension_regular_monthly),
            LabelingFunction(name="lf_pension_text_indicators", f=lf_pension_text_indicators),
            LabelingFunction(name="lf_pension_ultra_consistent", f=lf_pension_ultra_consistent),
            LabelingFunction(name="lf_pension_expected_range", f=lf_pension_expected_range),
            LabelingFunction(name="lf_not_pension_too_variable", f=lf_not_pension_too_variable),
            LabelingFunction(name="lf_not_pension_wrong_frequency", f=lf_not_pension_wrong_frequency),
            LabelingFunction(name="lf_not_pension_too_high", f=lf_not_pension_too_high),
        ]

# ===========================
# CLASSIFICATION FUNCTIONS
# ===========================

def apply_income_classification(user_profile: UserProfile, merchant_agg_df: pd.DataFrame):
    """Apply appropriate classifiers based on user profile - can run multiple"""

    active_classifiers = user_profile.get_active_classifiers()
    print(f"\n=== RUNNING {len(active_classifiers)} CLASSIFIERS ===")
    print(f"Active classifiers: {active_classifiers}")

    results = {}

    # Initialize result columns
    merchant_agg_df['is_salary'] = 0
    merchant_agg_df['salary_confidence'] = 0.0
    merchant_agg_df['is_work_income'] = 0
    merchant_agg_df['work_income_confidence'] = 0.0
    merchant_agg_df['is_pension'] = 0
    merchant_agg_df['pension_confidence'] = 0.0

    # Run salary classifier if needed
    if "salary" in active_classifiers:
        print("\n" + "="*50)
        print("RUNNING SALARY CLASSIFIER")
        print("="*50)
        salary_lfs, salary_model, merchant_agg_df = apply_salary_classification(user_profile, merchant_agg_df)
        results['salary'] = (salary_lfs, salary_model)

    # Run work income classifier if needed
    if "work_income" in active_classifiers:
        print("\n" + "="*50)
        print("RUNNING WORK INCOME CLASSIFIER")
        print("="*50)
        work_lfs, work_model, merchant_agg_df = apply_work_income_classification(user_profile, merchant_agg_df)
        results['work_income'] = (work_lfs, work_model)

    # Run pension classifier if needed
    if "pension" in active_classifiers:
        print("\n" + "="*50)
        print("RUNNING PENSION CLASSIFIER")
        print("="*50)
        pension_lfs, pension_model, merchant_agg_df = apply_pension_classification(user_profile, merchant_agg_df)
        results['pension'] = (pension_lfs, pension_model)

    # Summary of all results
    print("\n" + "="*60)
    print("FINAL CLASSIFICATION SUMMARY")
    print("="*60)

    total_transactions = len(merchant_agg_df)
    print(f"Total transactions analyzed: {total_transactions}")

    if "salary" in active_classifiers:
        salary_count = (merchant_agg_df['is_salary'] == 1).sum()
        high_conf_salary = (
            (merchant_agg_df['is_salary'] == 1) &
            (merchant_agg_df['salary_confidence'] > 0.7)
        ).sum()
        print(f"Salary predictions: {salary_count} ({salary_count/total_transactions*100:.1f}%)")
        print(f"High confidence salary: {high_conf_salary}")

    if "work_income" in active_classifiers:
        work_count = (merchant_agg_df['is_work_income'] == 1).sum()
        high_conf_work = (
            (merchant_agg_df['is_work_income'] == 1) &
            (merchant_agg_df['work_income_confidence'] > 0.7)
        ).sum()
        print(f"Work income predictions: {work_count} ({work_count/total_transactions*100:.1f}%)")
        print(f"High confidence work income: {high_conf_work}")

    if "pension" in active_classifiers:
        pension_count = (merchant_agg_df['is_pension'] == 1).sum()
        high_conf_pension = (
            (merchant_agg_df['is_pension'] == 1) &
            (merchant_agg_df['pension_confidence'] > 0.7)
        ).sum()
        print(f"Pension predictions: {pension_count} ({pension_count/total_transactions*100:.1f}%)")
        print(f"High confidence pension: {high_conf_pension}")

    # Check for overlaps (same transaction classified as multiple types)
    if len(active_classifiers) > 1:
        overlaps = 0
        if "salary" in active_classifiers and "work_income" in active_classifiers:
            both_salary_work = (
                (merchant_agg_df['is_salary'] == 1) &
                (merchant_agg_df['is_work_income'] == 1)
            ).sum()
            if both_salary_work > 0:
                print(f"Overlap (Salary + Work Income): {both_salary_work}")
                overlaps += both_salary_work

        if overlaps == 0:
            print("No overlapping classifications found ✓")

    return results, merchant_agg_df

def apply_salary_classification(user_profile: UserProfile, merchant_agg_df: pd.DataFrame):
    """Apply salary classification for employees"""
    print(f"\n=== APPLYING SALARY CLASSIFICATION ===")
    print(f"User sources: {[s.value for s in user_profile.income_sources]}")
    print(f"Thresholds: {user_profile.salary_thresholds}")

    # Create salary detector
    detector = SalaryDetector(user_profile)
    salary_lfs = detector.create_salary_labeling_functions()

    # Apply labeling functions
    applier = PandasLFApplier(lfs=salary_lfs)
    L_salary = applier.apply(merchant_agg_df)

    # Analyze performance
    lf_analysis = LFAnalysis(L=L_salary, lfs=salary_lfs)
    print(f"\nSalary LF Analysis:")
    print(lf_analysis.lf_summary())

    # Train model
    salary_model = LabelModel(cardinality=2, verbose=True)

    # Get class balance
    def get_binary_class_balance(L_matrix):
        votes = L_matrix[L_matrix != -1]
        if len(votes) == 0:
            return np.array([0.5, 0.5])
        positive_votes = np.sum(votes == 1)
        total_votes = len(votes)
        pos_ratio = positive_votes / total_votes if total_votes > 0 else 0.5
        return np.array([1 - pos_ratio, pos_ratio])

    class_balance = get_binary_class_balance(L_salary)
    print(f"Class balance: {class_balance}")

    # Train
    salary_model.fit(L_train=L_salary, n_epochs=500, log_freq=100, seed=42, class_balance=class_balance)

    # Predictions
    predictions = salary_model.predict(L=L_salary)
    probabilities = salary_model.predict_proba(L=L_salary)

    # Add to dataframe
    merchant_agg_df['is_salary'] = predictions
    merchant_agg_df['salary_confidence'] = probabilities[:, 1] if probabilities.shape[1] > 1 else probabilities[:, 0]

    # Results
    print(f"\nSalary Classification Results:")
    print(f"Total transactions: {len(merchant_agg_df)}")
    print(f"Predicted as salary: {(predictions == POSITIVE).sum()}")

    high_conf_salary = merchant_agg_df[
        (merchant_agg_df['is_salary'] == POSITIVE) &
        (merchant_agg_df['salary_confidence'] > 0.7)
    ]
    print(f"High confidence salary: {len(high_conf_salary)}")

    if len(high_conf_salary) > 0:
        print("\nTop salary predictions:")
        print(high_conf_salary[['CLEANED_TEXT', 'MERCHANT', 'amt_mean', 'amt_count', 'salary_confidence']].head())

    return salary_lfs, salary_model, merchant_agg_df

def apply_work_income_classification(user_profile: UserProfile, merchant_agg_df: pd.DataFrame):
    """Apply work income classification for freelancers/self-employed"""
    print(f"\n=== APPLYING WORK INCOME CLASSIFICATION ===")
    print(f"User sources: {[s.value for s in user_profile.income_sources]}")
    print(f"Thresholds: {user_profile.work_income_thresholds}")

    # Create work income detector
    detector = WorkIncomeDetector(user_profile)
    work_income_lfs = detector.create_work_income_labeling_functions()

    # Apply labeling functions
    applier = PandasLFApplier(lfs=work_income_lfs)
    L_work_income = applier.apply(merchant_agg_df)

    # Analyze performance
    lf_analysis = LFAnalysis(L=L_work_income, lfs=work_income_lfs)
    print(f"\nWork Income LF Analysis:")
    print(lf_analysis.lf_summary())

    # Train model
    work_income_model = LabelModel(cardinality=2, verbose=True)

    # Get class balance
    def get_binary_class_balance(L_matrix):
        votes = L_matrix[L_matrix != -1]
        if len(votes) == 0:
            return np.array([0.5, 0.5])
        positive_votes = np.sum(votes == 1)
        total_votes = len(votes)
        pos_ratio = positive_votes / total_votes if total_votes > 0 else 0.5
        return np.array([1 - pos_ratio, pos_ratio])

    class_balance = get_binary_class_balance(L_work_income)
    print(f"Class balance: {class_balance}")

    # Train
    work_income_model.fit(L_train=L_work_income, n_epochs=500, log_freq=100, seed=42, class_balance=class_balance)

    # Predictions
    predictions = work_income_model.predict(L=L_work_income)
    probabilities = work_income_model.predict_proba(L=L_work_income)

    # Add to dataframe
    merchant_agg_df['is_work_income'] = predictions
    merchant_agg_df['work_income_confidence'] = probabilities[:, 1] if probabilities.shape[1] > 1 else probabilities[:, 0]

    # Results
    print(f"\nWork Income Classification Results:")
    print(f"Total transactions: {len(merchant_agg_df)}")
    print(f"Predicted as work income: {(predictions == POSITIVE).sum()}")

    high_conf_work = merchant_agg_df[
        (merchant_agg_df['is_work_income'] == POSITIVE) &
        (merchant_agg_df['work_income_confidence'] > 0.7)
    ]
    print(f"High confidence work income: {len(high_conf_work)}")

    if len(high_conf_work) > 0:
        print("\nTop work income predictions:")
        print(high_conf_work[['CLEANED_TEXT', 'MERCHANT', 'amt_mean', 'amt_count', 'work_income_confidence']].head())

    return work_income_lfs, work_income_model, merchant_agg_df

def apply_pension_classification(user_profile: UserProfile, merchant_agg_df: pd.DataFrame):
    """Apply pension classification for retired users"""
    print(f"\n=== APPLYING PENSION CLASSIFICATION ===")
    print(f"User sources: {[s.value for s in user_profile.income_sources]}")
    print(f"Thresholds: {user_profile.pension_thresholds}")

    # Debug: Check data characteristics
    print(f"\nData overview:")
    print(f"Total transactions: {len(merchant_agg_df)}")
    print(f"Amount range: €{merchant_agg_df['amt_mean'].min():.2f} - €{merchant_agg_df['amt_mean'].max():.2f}")
    print(f"CV range: {merchant_agg_df['amt_cv'].min():.3f} - {merchant_agg_df['amt_cv'].max():.3f}")
    print(f"Delta days range: {merchant_agg_df['mean_delta_days'].min():.1f} - {merchant_agg_df['mean_delta_days'].max():.1f}")

    # Check for potential pension candidates
    potential_pensions = merchant_agg_df[
        (merchant_agg_df['amt_mean'] >= 150) &
        (merchant_agg_df['amt_cv'] <= 0.2) &
        (merchant_agg_df['mean_delta_days'] >= 20) &
        (merchant_agg_df['mean_delta_days'] <= 40)
    ]
    print(f"Potential pension candidates: {len(potential_pensions)}")

    if len(potential_pensions) > 0:
        print("Sample potential pensions:")
        print(potential_pensions[['CLEANED_TEXT', 'amt_mean', 'amt_cv', 'mean_delta_days', 'amt_count']].head())

    # Create pension detector
    detector = PensionDetector(user_profile)
    pension_lfs = detector.create_pension_labeling_functions()

    # Apply labeling functions
    applier = PandasLFApplier(lfs=pension_lfs)
    L_pension = applier.apply(merchant_agg_df)

    # Debug: Check LF outputs
    print(f"\nLF outputs summary:")
    for i, lf in enumerate(pension_lfs):
        lf_votes = L_pension[:, i]
        positive_votes = (lf_votes == 1).sum()
        negative_votes = (lf_votes == 0).sum()
        abstain_votes = (lf_votes == -1).sum()
        print(f"{lf.name}: +{positive_votes}, -{negative_votes}, abstain:{abstain_votes}")

    # Analyze performance
    lf_analysis = LFAnalysis(L=L_pension, lfs=pension_lfs)
    print(f"\nPension LF Analysis:")
    print(lf_analysis.lf_summary())

    # Check if we have any positive predictions
    positive_predictions = (L_pension == 1).any(axis=1).sum()
    if positive_predictions == 0:
        print("\nWARNING: No positive pension predictions found!")
        print("This might indicate:")
        print("1. No pension transactions in the data")
        print("2. Thresholds are too strict")
        print("3. Data format doesn't match expected patterns")

        # Return without training model
        merchant_agg_df['is_pension'] = 0
        merchant_agg_df['pension_confidence'] = 0.0
        return pension_lfs, None, merchant_agg_df

    # Train model
    pension_model = LabelModel(cardinality=2, verbose=True)

    # Get class balance
    def get_binary_class_balance(L_matrix):
        votes = L_matrix[L_matrix != -1]
        if len(votes) == 0:
            return np.array([0.5, 0.5])
        positive_votes = np.sum(votes == 1)
        total_votes = len(votes)
        pos_ratio = positive_votes / total_votes if total_votes > 0 else 0.01  # Avoid 0
        # Ensure neither class has 0 probability
        pos_ratio = max(0.01, min(0.99, pos_ratio))
        return np.array([1 - pos_ratio, pos_ratio])

    class_balance = get_binary_class_balance(L_pension)
    print(f"Class balance: {class_balance}")

    # Train
    pension_model.fit(L_train=L_pension, n_epochs=500, log_freq=100, seed=42, class_balance=class_balance)

    # Predictions
    predictions = pension_model.predict(L=L_pension)
    probabilities = pension_model.predict_proba(L=L_pension)

    # Add to dataframe
    merchant_agg_df['is_pension'] = predictions
    merchant_agg_df['pension_confidence'] = probabilities[:, 1] if probabilities.shape[1] > 1 else probabilities[:, 0]

    # Results
    print(f"\nPension Classification Results:")
    print(f"Total transactions: {len(merchant_agg_df)}")
    print(f"Predicted as pension: {(predictions == POSITIVE).sum()}")

    high_conf_pension = merchant_agg_df[
        (merchant_agg_df['is_pension'] == POSITIVE) &
        (merchant_agg_df['pension_confidence'] > 0.7)
    ]
    print(f"High confidence pension: {len(high_conf_pension)}")

    if len(high_conf_pension) > 0:
        print("\nTop pension predictions:")
        print(high_conf_pension[['CLEANED_TEXT', 'MERCHANT', 'amt_mean', 'amt_count', 'pension_confidence']].head())

    return pension_lfs, pension_model, merchant_agg_df

# ===========================
# ONBOARDING FUNCTIONS
# ===========================

def simulate_onboarding():
    """Simulate the multi-select onboarding process"""
    print("=== INCOME CLASSIFICATION ONBOARDING ===\n")

    # Question 1: Income sources (multi-select)
    print("Question 1: What income sources do you have? (Select all that apply)")
    print("Enter the numbers separated by commas (e.g., 1,3,5)")
    print("1. Full-time job")
    print("2. Part-time job")
    print("3. Freelance work")
    print("4. Self-employed/Business")
    print("5. Pension/Retirement income")

    income_choice = input("\nEnter your choices (e.g., 1,3): ").strip()

    # Parse multiple selections
    selected_numbers = []
    try:
        selected_numbers = [int(x.strip()) for x in income_choice.split(',')]
    except ValueError:
        print("Invalid input, defaulting to part-time job")
        selected_numbers = [2]

    # Map to income sources
    income_mapping = {
        1: IncomeSource.FULL_TIME,
        2: IncomeSource.PART_TIME,
        3: IncomeSource.FREELANCE,
        4: IncomeSource.SELF_EMPLOYED,
        5: IncomeSource.RETIRED
    }

    income_sources = set()
    for num in selected_numbers:
        if num in income_mapping:
            income_sources.add(income_mapping[num])

    if not income_sources:  # Fallback if nothing selected
        income_sources = {IncomeSource.PART_TIME}

    print(f"Selected income sources: {[source.value for source in income_sources]}")

    # Question 2: Primary income source (if multiple selected)
    primary_income = None
    if len(income_sources) > 1:
        print(f"\nQuestion 2: Which is your PRIMARY income source?")
        source_list = list(income_sources)
        for i, source in enumerate(source_list, 1):
            print(f"{i}. {source.value.replace('_', ' ').title()}")

        primary_choice = input(f"\nEnter your choice (1-{len(source_list)}): ").strip()
        try:
            primary_idx = int(primary_choice) - 1
            if 0 <= primary_idx < len(source_list):
                primary_income = source_list[primary_idx]
        except ValueError:
            pass

        if not primary_income:
            primary_income = source_list[0]  # Default to first
    else:
        primary_income = next(iter(income_sources))

    print(f"Primary income source: {primary_income.value}")

    # Question 3: Monthly income range
    print(f"\nQuestion 3: What's your approximate TOTAL monthly income? (EUR)")
    print("1. Under €1,500")
    print("2. €1,500 - €4,000")
    print("3. €4,000+")
    print("4. Prefer not to say")

    income_range_choice = input("\nEnter your choice (1-4): ").strip()

    income_mapping = {
        "1": "under_1500",
        "2": "1500_4000",
        "3": "4000_plus",
        "4": "1500_4000"  # Default to middle range
    }
    income_range = income_mapping.get(income_range_choice, "1500_4000")

    # Question 4: Payment frequencies (for each income source)
    payment_frequencies = {}

    for source in income_sources:
        if source in [IncomeSource.FULL_TIME, IncomeSource.PART_TIME]:
            print(f"\nQuestion 4a: How often are you paid from your {source.value.replace('_', ' ')} job?")
            print("1. Weekly")
            print("2. Every 2 weeks")
            print("3. Monthly")
            print("4. Irregular")

            freq_choice = input("\nEnter your choice (1-4): ").strip()

            freq_mapping = {
                "1": PaymentFrequency.WEEKLY,
                "2": PaymentFrequency.BIWEEKLY,
                "3": PaymentFrequency.MONTHLY,
                "4": PaymentFrequency.IRREGULAR
            }
            payment_frequencies[source] = freq_mapping.get(freq_choice, PaymentFrequency.MONTHLY)

        elif source in [IncomeSource.FREELANCE, IncomeSource.SELF_EMPLOYED]:
            print(f"\nQuestion 4b: How would you describe your {source.value.replace('_', ' ')} payment pattern?")
            print("1. Regular monthly payments")
            print("2. Project-based (irregular)")
            print("3. Mixed/Variable")

            freq_choice = input("\nEnter your choice (1-3): ").strip()

            freq_mapping = {
                "1": PaymentFrequency.MONTHLY,
                "2": PaymentFrequency.IRREGULAR,
                "3": PaymentFrequency.IRREGULAR
            }
            payment_frequencies[source] = freq_mapping.get(freq_choice, PaymentFrequency.IRREGULAR)

        elif source == IncomeSource.RETIRED:
            print(f"\nQuestion 4c: How often do you receive your pension?")
            print("1. Monthly")
            print("2. Other frequency")

            freq_choice = input("\nEnter your choice (1-2): ").strip()
            payment_frequencies[source] = PaymentFrequency.MONTHLY if freq_choice == "1" else PaymentFrequency.IRREGULAR

    return UserProfile(
        income_sources=income_sources,
        monthly_income_range=income_range,
        primary_income_source=primary_income,
        payment_frequencies=payment_frequencies
    )

def quick_setup_examples():
    """Quick setup examples for different scenarios"""
    print("=== QUICK SETUP EXAMPLES ===\n")

    # Example 1: Full-time employee only
    salary_only_profile = UserProfile(
        income_sources={IncomeSource.FULL_TIME},
        monthly_income_range="1500_4000",
        primary_income_source=IncomeSource.FULL_TIME,
        payment_frequencies={IncomeSource.FULL_TIME: PaymentFrequency.MONTHLY}
    )

    # Example 2: Full-time + Side hustle
    salary_plus_freelance_profile = UserProfile(
        income_sources={IncomeSource.FULL_TIME, IncomeSource.FREELANCE},
        monthly_income_range="1500_4000",
        primary_income_source=IncomeSource.FULL_TIME,
        payment_frequencies={
            IncomeSource.FULL_TIME: PaymentFrequency.MONTHLY,
            IncomeSource.FREELANCE: PaymentFrequency.IRREGULAR
        }
    )

    # Example 3: Retired + Consulting
    pension_plus_consulting_profile = UserProfile(
        income_sources={IncomeSource.RETIRED, IncomeSource.FREELANCE},
        monthly_income_range="1500_4000",
        primary_income_source=IncomeSource.RETIRED,
        payment_frequencies={
            IncomeSource.RETIRED: PaymentFrequency.MONTHLY,
            IncomeSource.FREELANCE: PaymentFrequency.IRREGULAR
        }
    )

    print("Created three example profiles:")
    print(f"1. Salary only: {[s.value for s in salary_only_profile.income_sources]}")
    print(f"   Active classifiers: {salary_only_profile.get_active_classifiers()}")
    print(f"2. Full-time + Freelance: {[s.value for s in salary_plus_freelance_profile.income_sources]}")
    print(f"   Active classifiers: {salary_plus_freelance_profile.get_active_classifiers()}")
    print(f"3. Retired + Consulting: {[s.value for s in pension_plus_consulting_profile.income_sources]}")
    print(f"   Active classifiers: {pension_plus_consulting_profile.get_active_classifiers()}")

    return salary_only_profile, salary_plus_freelance_profile, pension_plus_consulting_profile

# ===========================
# MAIN USAGE EXAMPLES
# ===========================

def main():
    """Main function with usage examples"""
    print("=== MULTI-INCOME CLASSIFICATION SYSTEM ===")
    print("Complete system loaded successfully!")
    print()
    print("Usage examples:")
    print()
    print("# 1. Interactive onboarding (multi-select):")
    print("user_profile = simulate_onboarding()")
    print()
    print("# 2. Quick examples:")
    print("salary_only, salary_plus_freelance, pension_plus_consulting = quick_setup_examples()")
    print()
    print("# 3. Apply classification:")
    print("results, updated_df = apply_income_classification(user_profile, merchant_agg_df)")
    print()
    print("# 4. Example scenarios:")
    print("# - Full-time only: Select '1' → Runs salary classifier")
    print("# - Full-time + Side hustle: Select '1,3' → Runs salary AND work income classifiers")
    print("# - Retired + Consulting: Select '5,3' → Runs pension AND work income classifiers")
    print()
    print("Ready to use! 🚀")

if __name__ == "__main__":
    main()

user_profile = simulate_onboarding()

# Correct way:
results, updated_df = apply_income_classification(user_profile, merchant_agg_df)

"""---

# Reusable category classification framework
"""

from typing import List

class CategoryClassifier:
    """Reusable framework for binary category classification using weak supervision"""

    def __init__(self, category_name: str, ft_model, dataframe: pd.DataFrame):
        self.category_name = category_name
        self.ft_model = ft_model
        self.df = dataframe
        self.POSITIVE = 1
        self.NEGATIVE = 0
        self.ABSTAIN = -1

        # Will be set by subclasses
        self.anchors = []
        self.anchor_system = None
        self.labeling_functions = []
        self.L_matrix = None
        self.label_model = None
        self.results = {}

    def setup_anchors(self, anchors: List[str], similarity_threshold: float = 0.6):
        """Setup FastText anchor system"""
        self.anchors = anchors
        self.anchor_system = FastTextAnchorSystem(
            self.ft_model, anchors, similarity_threshold
        )

    def create_labeling_functions(self) -> List[LabelingFunction]:
        """To be implemented by each category subclass"""
        raise NotImplementedError("Each category must implement its own LFs")

    def apply_labeling_functions(self):
        """Apply labeling functions and analyze"""
        self.labeling_functions = self.create_labeling_functions()

        applier = PandasLFApplier(lfs=self.labeling_functions)
        self.L_matrix = applier.apply(self.df)

        # Analyze LF performance
        lf_analysis = LFAnalysis(L=self.L_matrix, lfs=self.labeling_functions)
        print(f"\n{self.category_name} LF Analysis:")
        print(lf_analysis.lf_summary())

        return self.L_matrix

    def train_label_model(self, n_epochs: int = 500):
        """Train Snorkel label model"""
        if self.L_matrix is None:
            raise ValueError("Must apply labeling functions first")

        # Calculate class balance
        votes = self.L_matrix[self.L_matrix != -1]
        if len(votes) == 0:
            class_balance = np.array([0.5, 0.5])
        else:
            pos_ratio = np.sum(votes == 1) / len(votes)
            pos_ratio = max(0.01, min(0.99, pos_ratio))  # Smoothing
            class_balance = np.array([1 - pos_ratio, pos_ratio])

        print(f"{self.category_name} class balance: {class_balance}")

        # Train model
        self.label_model = LabelModel(cardinality=2, verbose=True)
        self.label_model.fit(
            L_train=self.L_matrix,
            n_epochs=n_epochs,
            log_freq=100,
            seed=42,
            class_balance=class_balance
        )

    def get_predictions(self, confidence_threshold: float = 0.8):
        """Get predictions and add to dataframe"""
        if self.label_model is None:
            raise ValueError("Must train label model first")

        probs = self.label_model.predict_proba(L=self.L_matrix)
        predictions = self.label_model.predict(L=self.L_matrix)

        # Add to dataframe
        label_col = f'is_{self.category_name.lower()}_weak_label'
        confidence_col = f'{self.category_name.lower()}_confidence'

        self.df[label_col] = predictions
        self.df[confidence_col] = probs[:, 1] if probs.shape[1] > 1 else probs[:, 0]

        # Get high confidence results
        high_confidence = self.df[
            (self.df[label_col] == self.POSITIVE) &
            (self.df[confidence_col] > confidence_threshold)
        ]

        # Store results
        self.results = {
            'total_transactions': len(self.df),
            'predicted_positive': (self.df[label_col] == self.POSITIVE).sum(),
            'high_confidence_positive': len(high_confidence),
            'abstentions': (self.df[label_col] == self.ABSTAIN).sum(),
            'high_confidence_examples': high_confidence
        }

        return self.results

    def run_full_pipeline(self, confidence_threshold: float = 0.8):
        """Run the complete pipeline"""
        print(f"\n=== Running {self.category_name} Classification Pipeline ===")

        # 1. Apply LFs
        self.apply_labeling_functions()

        # 2. Train label model
        self.train_label_model()

        # 3. Get predictions
        results = self.get_predictions(confidence_threshold)

        # 4. Print summary
        print(f"\n{self.category_name} Classification Results:")
        print(f"Total transactions: {results['total_transactions']}")
        print(f"Predicted as {self.category_name.lower()}: {results['predicted_positive']}")
        print(f"High confidence: {results['high_confidence_positive']}")

        if len(results['high_confidence_examples']) > 0:
            print(f"\nHigh confidence {self.category_name.lower()} examples:")
            display_cols = ['CLEANED_TEXT', 'MERCHANT', 'amt_mean', 'amt_count', f'{self.category_name.lower()}_confidence']
            print(results['high_confidence_examples'][display_cols].head())

        return results

# Reusable FastText Anchor System
class FastTextAnchorSystem:
    def __init__(self, ft_model, anchors: list, similarity_threshold: float = 0.5):
        self.ft = ft_model
        self.anchors = anchors
        self.similarity_threshold = similarity_threshold
        self.expanded_anchors = self._expand_anchors()

    def _expand_anchors(self, n_similar: int = 20):
        expanded_words = set(self.anchors)
        for word in self.anchors:
            try:
                similar_words = self.ft.get_nearest_neighbors(word, k=n_similar)
                for sim_score, sim_word in similar_words:
                    if sim_score >= self.similarity_threshold:
                        expanded_words.add(sim_word)
            except:
                continue
        print(f"Anchors expanded from {len(self.anchors)} to {len(expanded_words)} words")
        print(expanded_words)
        return expanded_words

    def get_text_similarity(self, text: str) -> float:
        if not text:
            return 0.0
        try:
            text_vec = self.ft.get_sentence_vector(text)
            similarities = []
            for anchor_word in self.expanded_anchors:
                try:
                    anchor_vec = self.ft.get_word_vector(anchor_word)
                    sim = np.dot(text_vec, anchor_vec) / (np.linalg.norm(text_vec) * np.linalg.norm(anchor_vec))
                    similarities.append(sim)
                except:
                    continue
            return max(similarities) if similarities else 0.0
        except:
            return 0.0

"""# Benefits

## Unemployment
"""

class UnemploymentBenefitsClassifier(CategoryClassifier):
    """Unemployment benefits classifier"""

    def __init__(self, ft_model, dataframe: pd.DataFrame):
        super().__init__("UnemploymentBenefits", ft_model, dataframe)


    def create_labeling_functions(self) -> List[LabelingFunction]:
        """Create unemployment-specific labeling functions"""

        def lf_unemployment_explicit(x):
            if pd.isna(x.CLEANED_TEXT):
                return self.ABSTAIN
            text_lower = x.CLEANED_TEXT.lower()
            unemployment_terms = [
                "france travail", "pole emploi", "ARE", "CSP", "ASS"
            ]
            if any(term in text_lower for term in unemployment_terms):
                return self.POSITIVE
            return self.NEGATIVE

        def lf_unemployment_monthly_pattern(x):
            # Unemployment benefits are typically regular, monthly, moderate amounts
            if (28 <= x.mean_delta_days <= 32 and x.amt_mean <= 5000):
                return self.POSITIVE
            return self.ABSTAIN

        def lf_unemployment_lumpsum_pattern(x):
            # Unemployment benefits can be in lumpsum if with ACRE and high amounts
            if (x.amt_mean > 5000):
                return self.POSITIVE
            return self.ABSTAIN


        return [
            LabelingFunction(name="lf_unemployment_explicit", f=lf_unemployment_explicit),
            LabelingFunction(name="lf_unemployment_monthly_pattern", f=lf_unemployment_monthly_pattern),
            LabelingFunction(name="lf_unemployment_lumpsum_pattern", f=lf_unemployment_lumpsum_pattern),
        ]

def extract_lf_results_to_excel(classifier, dataframe, filename="unemployment_lf_results.xlsx"):
    """Extract LF results per transaction group and export to Excel"""

    # Get the LF matrix
    L_matrix = classifier.L_matrix
    lf_names = [lf.name for lf in classifier.labeling_functions]

    # Create LF results DataFrame
    lf_results_df = pd.DataFrame(L_matrix, columns=lf_names)

    # Add original transaction data
    results_with_context = pd.concat([
        dataframe[['CLEANED_TEXT', 'MERCHANT', 'amt_mean', 'amt_count', 'mean_delta_days', 'amt_cv']].reset_index(drop=True),
        lf_results_df
    ], axis=1)

    # Add final predictions if they exist
    label_col = f'is_{classifier.category_name.lower()}_weak_label'
    confidence_col = f'{classifier.category_name.lower()}_confidence'

    if label_col in dataframe.columns:
        results_with_context[label_col] = dataframe[label_col].values
        results_with_context[confidence_col] = dataframe[confidence_col].values

    # Add summary columns
    results_with_context['total_lf_votes'] = (L_matrix != -1).sum(axis=1)
    results_with_context['positive_lf_votes'] = (L_matrix == 1).sum(axis=1)
    results_with_context['negative_lf_votes'] = (L_matrix == 0).sum(axis=1)
    results_with_context['has_conflicts'] = [
        len(set(row[row != -1])) > 1 if len(row[row != -1]) > 1 else False
        for row in L_matrix
    ]

    # Create readable LF result columns
    for i, lf_name in enumerate(lf_names):
        results_with_context[f'{lf_name}_readable'] = results_with_context[lf_name].map({
            1: 'POSITIVE', 0: 'NEGATIVE', -1: 'ABSTAIN'
        })

    # Export to Excel with multiple sheets
    with pd.ExcelWriter(filename, engine='openpyxl') as writer:
        # Sheet 1: All results
        results_with_context.to_excel(writer, sheet_name='All_Results', index=False)

        # Sheet 2: Only transactions where LFs fired
        active_results = results_with_context[results_with_context['total_lf_votes'] > 0]
        active_results.to_excel(writer, sheet_name='Active_LFs', index=False)

        # Sheet 3: Only positive predictions
        if label_col in results_with_context.columns:
            positive_results = results_with_context[results_with_context[label_col] == 1]
            if len(positive_results) > 0:
                positive_results.to_excel(writer, sheet_name='Positive_Predictions', index=False)

        # Sheet 4: Conflicts
        conflicts = results_with_context[results_with_context['has_conflicts']]
        if len(conflicts) > 0:
            conflicts.to_excel(writer, sheet_name='Conflicts', index=False)

        # Sheet 5: LF Summary Statistics
        lf_summary = create_lf_summary(L_matrix, lf_names, dataframe)
        lf_summary.to_excel(writer, sheet_name='LF_Summary', index=False)

    print(f"Results exported to {filename}")
    return results_with_context

def create_lf_summary(L_matrix, lf_names, dataframe):
    """Create summary statistics for each LF"""
    summary_data = []

    for i, lf_name in enumerate(lf_names):
        lf_votes = L_matrix[:, i]

        positive_votes = np.sum(lf_votes == 1)
        negative_votes = np.sum(lf_votes == 0)
        abstentions = np.sum(lf_votes == -1)
        total_votes = positive_votes + negative_votes
        coverage = total_votes / len(lf_votes) if len(lf_votes) > 0 else 0

        summary_data.append({
            'LF_Name': lf_name,
            'Positive_Votes': positive_votes,
            'Negative_Votes': negative_votes,
            'Abstentions': abstentions,
            'Total_Votes': total_votes,
            'Coverage': coverage,
            'Positive_Rate': positive_votes / total_votes if total_votes > 0 else 0
        })

    return pd.DataFrame(summary_data)

# Usage after running your classifier
unemployment_classifier = UnemploymentBenefitsClassifier(ft, merchant_agg_df)
unemployment_results = unemployment_classifier.run_full_pipeline(confidence_threshold=0.6)

# Export LF results to Excel
results_df = extract_lf_results_to_excel(
    unemployment_classifier,
    merchant_agg_df,
    "unemployment_lf_detailed_results.xlsx"
)

"""## Social"""

import re

class SocialBenefitsClassifier(CategoryClassifier):
    """Social benefits classifier"""

    def __init__(self, ft_model, dataframe: pd.DataFrame):
        super().__init__("SocialBenefits", ft_model, dataframe)


    def create_labeling_functions(self) -> List[LabelingFunction]:
        """Create social-specific labeling functions"""

        def lf_social_explicit(x):
            if pd.isna(x.CLEANED_TEXT):
                return self.ABSTAIN
            text_lower = x.CLEANED_TEXT.lower()
            social_terms = [
                "caf", "rsa", "prime d'activite", "allocations familiales", "paje", "cmg",
                "ars", "asf", "aeeh", "ajpp", "apl", "alf", "als", "cheque energie", "bourse"
            ]
            for term in social_terms:
                if re.search(rf"\b{re.escape(term)}\b", text_lower):
                    return self.POSITIVE
            return self.NEGATIVE


        def lf_social_monthly_pattern(x):
            # Unemployment benefits are typically regular, monthly, moderate amounts
            if (28 <= x.mean_delta_days <= 32 and x.amt_mean <= 1000):
                return self.POSITIVE
            return self.ABSTAIN

        def lf_social_min_pattern(x):
            text_lower = x.CLEANED_TEXT.lower()
            social_terms = [
               "Allocations familiales"
            ]
            if any(term in text_lower for term in social_terms):
                self.ABSTAIN
            elif (x.amt_mean > 100):
                return self.POSITIVE
            return self.NEGATIVE


        return [
            LabelingFunction(name="lf_social_explicit", f=lf_social_explicit),
            LabelingFunction(name="lf_social_monthly_pattern", f=lf_social_monthly_pattern),
            LabelingFunction(name="lf_social_min_pattern", f=lf_social_min_pattern),
        ]

# Usage after running your classifier
social_classifier = SocialBenefitsClassifier(ft, merchant_agg_df)
social_results = social_classifier.run_full_pipeline(confidence_threshold=0.6)

# Export LF results to Excel
results_df = extract_lf_results_to_excel(
    social_classifier,
    merchant_agg_df,
    "social_lf_detailed_results.xlsx"
)

"""# Pension

Covered in the 3rd version of the Salary section

# Investment income
"""

"""
Investment Income Classifier using the reusable CategoryClassifier framework
"""

import pandas as pd
import numpy as np
import re
from snorkel.labeling import LabelingFunction
from typing import List

class InvestmentIncomeClassifier(CategoryClassifier):
    """Investment income classifier using weak supervision framework"""

    def __init__(self, ft_model, dataframe: pd.DataFrame, user_profile=None):
        super().__init__("Investment", ft_model, dataframe)
        self.user_profile = user_profile
        self.thresholds = self._calculate_investment_thresholds()

        # Investment-specific anchor words for FastText expansion
        self.investment_anchor_terms = [
            "dividende", "interet", "coupon", "gain", "profit",
            "rachat", "fonds", "action", "obligation", "titre",
            "dividends", "interest", "dividend", "fund", "funds"
        ]

        # Comprehensive investment income terms organized by category
        self.investment_terms = {
            # Dividends
            "dividends": ["dividende", "dividendes", "div", "dividend", "dividends"],

            # Interest
            "interest": ["interet", "intérêt", "interets", "intérêts", "int", "interest",
                        "coupon", "coupons", "rendement", "yield"],

            # Capital gains
            "capital_gains": ["plus[- ]?value", "plus[- ]?values", "gain", "gains",
                             "capital", "profit", "benefice", "bénéfice"],

            # Fund operations
            "funds": ["opcr", "opcrachat", "rachat", "parts", "fonds", "fund", "funds",
                     "sicav", "fcpi", "scpi", "etf", "tracker"],

            # Investment platforms/brokers
            "brokers": ["degiro", "interactive brokers", "saxo", "binck", "boursorama",
                       "fortuneo", "credit agricole titres", "bnp paribas securities"],

            # Investment instruments
            "instruments": ["action", "actions", "obligation", "obligations", "titre",
                           "titres", "warrant", "warrants", "option", "options"]
        }

        # Flatten all terms for easy searching
        self.all_investment_terms = []
        for category_terms in self.investment_terms.values():
            self.all_investment_terms.extend(category_terms)

        # Setup FastText anchors
        self.setup_anchors(self.investment_anchor_terms, similarity_threshold=0.65)

    def _calculate_investment_thresholds(self) -> dict:
        """Calculate thresholds for investment income detection"""
        base_thresholds = {
            'min_amount': 10,        # Minimum per transaction
            'max_amount': 50000,     # Maximum reasonable
            'quarterly_min': 50,     # Minimum for quarterly patterns
            'annual_min': 100,       # Minimum for annual patterns
            'max_cv': 2.0,          # High CV tolerance (investment returns vary)
            'min_transactions': 1    # Single transactions can be investment income
        }

        # Adjust based on user's income level if available
        if self.user_profile and hasattr(self.user_profile, 'monthly_income_range'):
            if self.user_profile.monthly_income_range == "4000_plus":
                base_thresholds.update({
                    'min_amount': 25,
                    'quarterly_min': 200,
                    'annual_min': 500
                })
            elif self.user_profile.monthly_income_range == "under_1500":
                base_thresholds.update({
                    'min_amount': 5,
                    'quarterly_min': 25,
                    'annual_min': 50
                })

        return base_thresholds

    def create_labeling_functions(self) -> List[LabelingFunction]:
        """Create investment-specific labeling functions"""

        def lf_investment_explicit_terms(x):
            """Detect investment income based on explicit terms"""
            if pd.isna(x.CLEANED_TEXT) or x.CLEANED_TEXT == "":
                return self.ABSTAIN

            text_lower = x.CLEANED_TEXT.lower()

            # Check for explicit investment terms
            for term in self.all_investment_terms:
                if "?" in term or "[" in term:  # Handle regex patterns
                    if re.search(term, text_lower):
                        if x.amt_mean >= self.thresholds['min_amount']:
                            return self.POSITIVE
                else:
                    if re.search(rf"\b{re.escape(term)}\b", text_lower):
                        if x.amt_mean >= self.thresholds['min_amount']:
                            return self.POSITIVE

            return self.ABSTAIN

        def lf_investment_fasttext_similarity(x):
            """Detect investment income using FastText similarity"""
            if not self.anchor_system or pd.isna(x.CLEANED_TEXT) or x.CLEANED_TEXT == "":
                return self.ABSTAIN

            similarity = self.anchor_system.get_text_similarity(x.CLEANED_TEXT)

            # High similarity with minimum amount
            if similarity >= 0.7 and x.amt_mean >= self.thresholds['min_amount']:
                return self.POSITIVE
            # Lower similarity but higher amount threshold
            elif similarity >= 0.6 and x.amt_mean >= self.thresholds['quarterly_min']:
                return self.POSITIVE

            return self.ABSTAIN

        def lf_investment_quarterly_pattern(x):
            """Detect quarterly dividend patterns"""
            if x.amt_mean <= 0 or x.amt_count < 2:
                return self.ABSTAIN

            # Quarterly pattern: ~90-95 days between payments
            is_quarterly = 85 <= x.mean_delta_days <= 100
            has_reasonable_amount = x.amt_mean >= self.thresholds['quarterly_min']
            moderate_consistency = x.amt_cv <= 0.5  # Dividends can vary

            if is_quarterly and has_reasonable_amount and moderate_consistency:
                return self.POSITIVE

            return self.ABSTAIN

        def lf_investment_annual_pattern(x):
            """Detect annual investment patterns"""
            if x.amt_mean <= 0 or x.amt_count < 2:
                return self.ABSTAIN

            # Annual pattern: ~365 days
            is_annual = 350 <= x.mean_delta_days <= 380
            has_reasonable_amount = x.amt_mean >= self.thresholds['annual_min']
            is_consistent = x.amt_cv <= 0.3  # Annual payments more consistent

            if is_annual and has_reasonable_amount and is_consistent:
                return self.POSITIVE

            return self.ABSTAIN

        def lf_investment_semi_annual(x):
            """Detect semi-annual patterns (bonds, REITs)"""
            if x.amt_mean <= 0 or x.amt_count < 2:
                return self.ABSTAIN

            # Semi-annual: ~180 days
            is_semi_annual = 170 <= x.mean_delta_days <= 190
            has_reasonable_amount = x.amt_mean >= self.thresholds['quarterly_min']

            if is_semi_annual and has_reasonable_amount:
                return self.POSITIVE

            return self.ABSTAIN

        def lf_investment_broker_source(x):
            """Detect payments from known investment brokers"""
            if pd.isna(x.MERCHANT) and (pd.isna(x.CLEANED_TEXT) or x.CLEANED_TEXT == ""):
                return self.ABSTAIN

            # Check both merchant name and transaction text
            text_to_check = ""
            if not pd.isna(x.MERCHANT):
                text_to_check += x.MERCHANT.lower() + " "
            if not pd.isna(x.CLEANED_TEXT):
                text_to_check += x.CLEANED_TEXT.lower()

            # Check for known investment brokers
            for broker in self.investment_terms["brokers"]:
                if broker in text_to_check:
                    if x.amt_mean >= self.thresholds['min_amount']:
                        return self.POSITIVE

            return self.ABSTAIN

        def lf_investment_amount_patterns(x):
            """Detect investment-like amount patterns"""
            if x.amt_mean <= 0:
                return self.ABSTAIN

            is_reasonable_amount = (
                self.thresholds['min_amount'] <= x.amt_mean <= self.thresholds['max_amount']
            )

            # Not too regular (excludes salary) but not too irregular
            moderate_variability = 0.1 <= x.amt_cv <= self.thresholds['max_cv']

            # Check for "dividend-like" amounts (often round numbers)
            amount_str = str(int(x.amt_mean))
            ends_in_round = amount_str.endswith(('0', '5'))

            if is_reasonable_amount and moderate_variability:
                return self.POSITIVE
            elif is_reasonable_amount and ends_in_round and x.amt_count >= 2:
                return self.POSITIVE

            return self.ABSTAIN

        def lf_not_investment_salary_like(x):
            """Negative LF: Very regular, large payments are likely salary"""
            if x.amt_mean <= 0:
                return self.ABSTAIN

            # Very regular patterns with large amounts
            is_very_regular = (
                (26 <= x.mean_delta_days <= 32) or  # Monthly
                (13 <= x.mean_delta_days <= 16) or  # Bi-weekly
                (6 <= x.mean_delta_days <= 8)       # Weekly
            )

            is_very_consistent = x.amt_cv < 0.1
            is_large_amount = x.amt_mean > 1000

            if is_very_regular and is_very_consistent and is_large_amount:
                return self.NEGATIVE

            return self.ABSTAIN

        def lf_not_investment_small_frequent(x):
            """Negative LF: Very small, frequent payments unlikely to be investment"""
            if x.amt_mean < 5 and x.amt_count > 10:
                return self.NEGATIVE
            return self.ABSTAIN

        # Return list of labeling functions
        return [
            LabelingFunction(name="lf_investment_explicit_terms", f=lf_investment_explicit_terms),
            LabelingFunction(name="lf_investment_fasttext_similarity", f=lf_investment_fasttext_similarity),
            LabelingFunction(name="lf_investment_quarterly_pattern", f=lf_investment_quarterly_pattern),
            LabelingFunction(name="lf_investment_annual_pattern", f=lf_investment_annual_pattern),
            LabelingFunction(name="lf_investment_semi_annual", f=lf_investment_semi_annual),
            LabelingFunction(name="lf_investment_broker_source", f=lf_investment_broker_source),
            LabelingFunction(name="lf_investment_amount_patterns", f=lf_investment_amount_patterns),
            LabelingFunction(name="lf_not_investment_salary_like", f=lf_not_investment_salary_like),
            LabelingFunction(name="lf_not_investment_small_frequent", f=lf_not_investment_small_frequent),
        ]


# Usage example
def create_investment_classifier(ft_model, merchant_agg_df, user_profile=None):
    """Create and run investment income classifier"""

    # Create classifier instance
    classifier = InvestmentIncomeClassifier(ft_model, merchant_agg_df, user_profile)

    # Run full pipeline
    results = classifier.run_full_pipeline(confidence_threshold=0.7)

    return classifier, results


# Example usage:
"""
# Assuming you have ft_model, merchant_agg_df, and user_profile ready
investment_classifier, results = create_investment_classifier(
    ft_model=ft,
    merchant_agg_df=merchant_agg_df,
    user_profile=user_profile
)

# Access results
print(f"Investment income transactions found: {results['predicted_positive']}")
print(f"High confidence: {results['high_confidence_positive']}")

# Access the updated dataframe with predictions
updated_df = investment_classifier.df
print(updated_df[['CLEANED_TEXT', 'is_investment_weak_label', 'investment_confidence']].head())
"""

# Usage after running your classifier
investment_classifier = InvestmentIncomeClassifier(ft, merchant_agg_df)
investment_results = investment_classifier.run_full_pipeline(confidence_threshold=0.6)

# Export LF results to Excel
results_df = extract_lf_results_to_excel(
    investment_classifier,
    merchant_agg_df,
    "investment_lf_detailed_results.xlsx"
)

"""# Savings income"""

"""
Savings Income Classifier - Separate from Investment Income
Handles savings accounts, CDs, money market accounts, and other low-risk interest
"""

import pandas as pd
import numpy as np
import re
from snorkel.labeling import LabelingFunction
from typing import List

class SavingsIncomeClassifier(CategoryClassifier):
    """Savings income classifier for low-risk interest income"""

    def __init__(self, ft_model, dataframe: pd.DataFrame, user_profile=None):
        super().__init__("Savings", ft_model, dataframe)
        self.user_profile = user_profile
        self.thresholds = self._calculate_savings_thresholds()

        # Savings-specific anchor words
        self.savings_anchor_terms = [
            "interet", "interest", "epargne", "savings", "livret",
            "compte", "deposit", "cd", "terme", "placement"
        ]

        # Savings-specific terms
        self.savings_terms = {
            # Savings accounts
            "savings_accounts": ["livret", "livret a", "ldds", "pel", "cel",
                               "savings", "epargne", "épargne"],

            # Interest terms
            "interest": ["interet", "intérêt", "interets", "intérêts",
                        "interest", "int", "rendement"],

            # Bank account types
            "account_types": ["compte", "account", "deposit", "depot", "dépôt"],

            # Time deposits
            "time_deposits": ["terme", "term", "cd", "certificat", "certificate",
                            "placement", "fixed"],

            # Money market
            "money_market": ["monetaire", "monétaire", "money market", "mmda"],

            # Specific French savings products
            "french_savings": ["livret a", "livret bleu", "livret jeune",
                             "livret developpement durable", "ldds", "pel", "cel"]
        }

        # Flatten terms
        self.all_savings_terms = []
        for category_terms in self.savings_terms.values():
            self.all_savings_terms.extend(category_terms)

        # Setup FastText anchors
        self.setup_anchors(self.savings_anchor_terms, similarity_threshold=0.7)

    def _calculate_savings_thresholds(self) -> dict:
        """Calculate thresholds for savings income detection"""
        base_thresholds = {
            'min_amount': 0.01,      # Can be very small (low interest rates)
            'max_amount': 5000,      # Usually not huge amounts
            'monthly_min': 0.50,     # Minimum for monthly patterns
            'quarterly_min': 1.50,   # Minimum for quarterly patterns
            'annual_min': 5.00,      # Minimum for annual patterns
            'max_cv': 0.3,          # Should be very consistent (unlike investments)
            'min_transactions': 2    # Need some regularity
        }

        # Adjust based on user's income/savings level
        if self.user_profile and hasattr(self.user_profile, 'monthly_income_range'):
            if self.user_profile.monthly_income_range == "4000_plus":
                base_thresholds.update({
                    'min_amount': 1.0,
                    'monthly_min': 5.0,
                    'quarterly_min': 15.0,
                    'annual_min': 50.0
                })
            elif self.user_profile.monthly_income_range == "under_1500":
                # Keep very low thresholds for lower income
                pass

        return base_thresholds

    def create_labeling_functions(self) -> List[LabelingFunction]:
        """Create savings-specific labeling functions"""

        def lf_savings_explicit_terms(x):
            """Detect savings income based on explicit terms"""
            if pd.isna(x.CLEANED_TEXT) or x.CLEANED_TEXT == "":
                return self.ABSTAIN

            text_lower = x.CLEANED_TEXT.lower()

            # Check for explicit savings terms
            for term in self.all_savings_terms:
                if re.search(rf"\b{re.escape(term)}\b", text_lower):
                    if x.amt_mean >= self.thresholds['min_amount']:
                        return self.POSITIVE

            return self.ABSTAIN

        def lf_savings_fasttext_similarity(x):
            """Detect savings income using FastText similarity"""
            if not self.anchor_system or pd.isna(x.CLEANED_TEXT) or x.CLEANED_TEXT == "":
                return self.ABSTAIN

            similarity = self.anchor_system.get_text_similarity(x.CLEANED_TEXT)

            # Higher threshold for savings (more specific terms)
            if similarity >= 0.75 and x.amt_mean >= self.thresholds['min_amount']:
                return self.POSITIVE

            return self.ABSTAIN

        def lf_savings_monthly_regular(x):
            """Detect monthly savings interest (most common pattern)"""
            if x.amt_mean <= 0 or x.amt_count < 3:  # Need several occurrences
                return self.ABSTAIN

            # Monthly pattern: 28-32 days
            is_monthly = 28 <= x.mean_delta_days <= 32
            has_reasonable_amount = x.amt_mean >= self.thresholds['monthly_min']
            is_very_consistent = x.amt_cv <= self.thresholds['max_cv']  # Savings very consistent

            if is_monthly and has_reasonable_amount and is_very_consistent:
                return self.POSITIVE

            return self.ABSTAIN

        def lf_savings_quarterly_regular(x):
            """Detect quarterly savings interest"""
            if x.amt_mean <= 0 or x.amt_count < 2:
                return self.ABSTAIN

            # Quarterly: 88-95 days
            is_quarterly = 88 <= x.mean_delta_days <= 95
            has_reasonable_amount = x.amt_mean >= self.thresholds['quarterly_min']
            is_very_consistent = x.amt_cv <= self.thresholds['max_cv']

            if is_quarterly and has_reasonable_amount and is_very_consistent:
                return self.POSITIVE

            return self.ABSTAIN

        def lf_savings_annual_regular(x):
            """Detect annual savings interest (CDs, etc.)"""
            if x.amt_mean <= 0 or x.amt_count < 2:
                return self.ABSTAIN

            # Annual: 360-370 days
            is_annual = 360 <= x.mean_delta_days <= 370
            has_reasonable_amount = x.amt_mean >= self.thresholds['annual_min']
            is_very_consistent = x.amt_cv <= self.thresholds['max_cv']

            if is_annual and has_reasonable_amount and is_very_consistent:
                return self.POSITIVE

            return self.ABSTAIN

        def lf_savings_bank_context(x):
            """Detect savings based on bank context"""
            if pd.isna(x.MERCHANT) and (pd.isna(x.CLEANED_TEXT) or x.CLEANED_TEXT == ""):
                return self.ABSTAIN

            # Common bank names with savings context
            bank_indicators = [
                "credit agricole", "bnp", "societe generale", "lcl",
                "caisse epargne", "banque populaire", "credit mutuel",
                "hsbc", "ing", "boursorama", "fortuneo"
            ]

            text_to_check = ""
            if not pd.isna(x.MERCHANT):
                text_to_check += x.MERCHANT.lower() + " "
            if not pd.isna(x.CLEANED_TEXT):
                text_to_check += x.CLEANED_TEXT.lower()

            # Look for bank + savings context
            has_bank = any(bank in text_to_check for bank in bank_indicators)
            has_savings_context = any(term in text_to_check for term in
                                    ["interet", "interest", "epargne", "livret", "placement"])

            if has_bank and has_savings_context and x.amt_mean >= self.thresholds['min_amount']:
                return self.POSITIVE

            return self.ABSTAIN

        def lf_savings_small_regular_amounts(x):
            """Detect characteristic small, very regular amounts"""
            if x.amt_mean <= 0 or x.amt_count < 3:
                return self.ABSTAIN

            # Small amounts (typical of current low interest rates)
            is_small_amount = self.thresholds['min_amount'] <= x.amt_mean <= 100

            # Very regular (monthly or quarterly)
            is_regular = (
                (28 <= x.mean_delta_days <= 32) or  # Monthly
                (88 <= x.mean_delta_days <= 95)     # Quarterly
            )

            # Very consistent (savings interest is predictable)
            is_very_consistent = x.amt_cv <= 0.2

            if is_small_amount and is_regular and is_very_consistent:
                return self.POSITIVE

            return self.ABSTAIN

        def lf_not_savings_investment_like(x):
            """Negative LF: Variable amounts are more likely investments"""
            if x.amt_mean <= 0:
                return self.ABSTAIN

            # High variability suggests investments, not savings
            is_highly_variable = x.amt_cv > 1.0

            # Large amounts with high variability are likely investment returns
            is_large_and_variable = x.amt_mean > 500 and x.amt_cv > 0.5

            if is_highly_variable or is_large_and_variable:
                return self.NEGATIVE

            return self.ABSTAIN

        def lf_not_savings_one_time(x):
            """Negative LF: One-time large payments unlikely to be savings"""
            if x.amt_count == 1 and x.amt_mean > 1000:
                return self.NEGATIVE
            return self.ABSTAIN

        def lf_savings_naf_codes(x):
            """NAF codes that correspond to banks and financial institutions offering savings"""
            if pd.isna(x.NAF_CODE):
                return self.ABSTAIN

            # NAF codes for banks, credit institutions, and financial services
            savings_naf_codes = [
                "64.1", "64.11", "64.11Z",  # Central banking, monetary institutions
                "64.19", "64.19Z",          # Other monetary intermediation
                "64.2", "64.20", "64.20Z",  # Activities of holding companies
                "64.9", "64.91", "64.91Z",  # Financial leasing
                "64.92", "64.92Z",          # Other credit granting
                "64.99", "64.99Z",          # Other financial service activities
                "65.1", "65.11", "65.11Z",  # Life insurance
                "65.12", "65.12Z",          # Non-life insurance
                "66.1", "66.11", "66.11Z",  # Administration of financial markets
                "66.12", "66.12Z",          # Security and commodity contracts brokerage
                "66.19", "66.19Z",          # Other activities auxiliary to financial services
                "66.2", "66.21", "66.21Z",  # Risk and damage evaluation
                "66.22", "66.22Z",          # Activities of insurance agents and brokers
                "66.29", "66.29Z",          # Other activities auxiliary to insurance and pension funding
                "66.3", "66.30", "66.30Z",  # Fund management activities
            ]

            if str(x.NAF_CODE).strip() in savings_naf_codes:
                if x.amt_mean >= self.thresholds['min_amount']:
                    return self.POSITIVE
            return self.ABSTAIN

        def lf_savings_bank_merchants(x):
            """Known banks and financial institutions that offer savings products"""
            if pd.isna(x.MERCHANT):
                return self.ABSTAIN

            merchant_text = str(x.MERCHANT).strip()

            # Major banks and financial institutions (focusing on traditional banks)
            savings_merchants = [
                # French banks
                "BNP Paribas", "Crédit Agricole", "Société Générale", "Crédit Mutuel",
                "Banque Populaire", "Caisse d'Épargne", "LCL", "La Banque Postale",
                "Crédit Coopératif", "Banque Palatine", "CIC", "Crédit du Nord",

                # European banks
                "ING", "Deutsche Bank", "Commerzbank", "UniCredit", "Intesa Sanpaolo",
                "Santander", "BBVA", "ABN AMRO", "Rabobank", "KBC", "Belfius",
                "Erste Group", "Raiffeisen", "Nordea", "Danske Bank", "SEB",
                "Swedbank", "DNB", "SpareBank", "Handelsbanken",

                # UK banks
                "Barclays", "HSBC", "Lloyds", "Royal Bank of Scotland", "NatWest",
                "TSB", "Metro Bank", "Santander UK", "First Direct", "Halifax",
                "Bank of Scotland", "Nationwide",

                # US banks
                "JPMorgan Chase", "Bank of America", "Wells Fargo", "Citigroup",
                "Goldman Sachs", "Morgan Stanley", "US Bank", "PNC Bank",
                "Capital One", "TD Bank", "BB&T", "SunTrust", "Regions Bank",

                # Online/digital banks known for savings
                "Marcus", "Ally Bank", "American Express Bank", "Discover Bank",
                "Capital One 360", "CIT Bank", "Synchrony Bank", "Barclays US",
                "HSBC Direct", "ING Direct", "Boursorama", "Fortuneo", "Hello Bank",
                "N26", "Revolut", "Monzo", "Starling Bank",

                # Credit unions and savings institutions
                "Navy Federal", "USAA", "Pentagon Federal", "Alliant Credit Union",
                "American Express", "Vanguard", "Fidelity", "Charles Schwab"
            ]

            # Check for exact match first
            if merchant_text in savings_merchants:
                if x.amt_mean >= self.thresholds['min_amount']:
                    return self.POSITIVE

            # Check for partial matches (case-insensitive)
            merchant_lower = merchant_text.lower()
            for bank in savings_merchants:
                if bank.lower() in merchant_lower or merchant_lower in bank.lower():
                    if x.amt_mean >= self.thresholds['min_amount']:
                        return self.POSITIVE

            return self.ABSTAIN

        return [
            LabelingFunction(name="lf_savings_explicit_terms", f=lf_savings_explicit_terms),
            LabelingFunction(name="lf_savings_fasttext_similarity", f=lf_savings_fasttext_similarity),
            LabelingFunction(name="lf_savings_monthly_regular", f=lf_savings_monthly_regular),
            LabelingFunction(name="lf_savings_quarterly_regular", f=lf_savings_quarterly_regular),
            LabelingFunction(name="lf_savings_annual_regular", f=lf_savings_annual_regular),
            LabelingFunction(name="lf_savings_bank_context", f=lf_savings_bank_context),
            LabelingFunction(name="lf_savings_small_regular_amounts", f=lf_savings_small_regular_amounts),
            LabelingFunction(name="lf_savings_naf_codes", f=lf_savings_naf_codes),
            LabelingFunction(name="lf_savings_bank_merchants", f=lf_savings_bank_merchants),
            LabelingFunction(name="lf_not_savings_investment_like", f=lf_not_savings_investment_like),
            LabelingFunction(name="lf_not_savings_one_time", f=lf_not_savings_one_time),
        ]


# Updated Investment Income Classifier (adjusted to exclude savings-like patterns)
class InvestmentIncomeClassifier(CategoryClassifier):
    """Investment income classifier - excludes savings income"""

    def __init__(self, ft_model, dataframe: pd.DataFrame, user_profile=None):
        super().__init__("Investment", ft_model, dataframe)
        self.user_profile = user_profile
        self.thresholds = self._calculate_investment_thresholds()

        # Investment-specific anchors (excluding savings terms)
        self.investment_anchor_terms = [
            "dividende", "dividend", "gain", "profit", "capital",
            "rachat", "fonds", "action", "obligation", "opcr"  # Removed generic "interet"
        ]

        # Investment terms (more focused, excluding savings overlap)
        self.investment_terms = {
            # Dividends (clear investment signal)
            "dividends": ["dividende", "dividendes", "div", "dividend", "dividends"],

            # Capital gains (clear investment signal)
            "capital_gains": ["plus[- ]?value", "plus[- ]?values", "gain", "gains",
                             "capital", "profit", "benefice", "bénéfice"],

            # Fund operations (clear investment signal)
            "funds": ["opcr", "opcrachat", "rachat", "parts", "fonds", "fund", "funds",
                     "sicav", "fcpi", "scpi", "etf", "tracker"],

            # Investment platforms/brokers
            "brokers": ["degiro", "interactive brokers", "saxo", "binck",
                       "credit agricole titres", "bnp paribas securities"],

            # Investment instruments
            "instruments": ["action", "actions", "obligation", "obligations",
                           "warrant", "warrants", "option", "options"]
        }

        self.all_investment_terms = []
        for category_terms in self.investment_terms.values():
            self.all_investment_terms.extend(category_terms)

        self.setup_anchors(self.investment_anchor_terms, similarity_threshold=0.65)

    def _calculate_investment_thresholds(self) -> dict:
        """Calculate thresholds for investment income - adjusted to exclude savings"""
        base_thresholds = {
            'min_amount': 25,        # Higher minimum (exclude small savings interest)
            'max_amount': 50000,
            'quarterly_min': 50,
            'annual_min': 100,
            'max_cv': 2.0,          # High CV tolerance
            'min_cv': 0.3,          # NEW: Minimum CV to exclude very regular savings
        }

        if self.user_profile and hasattr(self.user_profile, 'monthly_income_range'):
            if self.user_profile.monthly_income_range == "4000_plus":
                base_thresholds.update({
                    'min_amount': 50,    # Even higher for wealthy users
                    'quarterly_min': 200,
                    'annual_min': 500
                })

        return base_thresholds

    def create_labeling_functions(self) -> List[LabelingFunction]:
        """Investment LFs - updated to exclude savings patterns"""

        def lf_investment_explicit_terms(x):
            """Detect investment income - excluding generic interest terms"""
            if pd.isna(x.CLEANED_TEXT) or x.CLEANED_TEXT == "":
                return self.ABSTAIN

            text_lower = x.CLEANED_TEXT.lower()

            for term in self.all_investment_terms:
                if "?" in term or "[" in term:
                    if re.search(term, text_lower):
                        if x.amt_mean >= self.thresholds['min_amount']:
                            return self.POSITIVE
                else:
                    if re.search(rf"\b{re.escape(term)}\b", text_lower):
                        if x.amt_mean >= self.thresholds['min_amount']:
                            return self.POSITIVE

            return self.ABSTAIN

        def lf_investment_variable_amounts(x):
            """Detect investment income by amount variability (vs savings consistency)"""
            if x.amt_mean <= 0 or x.amt_count < 2:
                return self.ABSTAIN

            # Investment returns are typically more variable than savings
            has_reasonable_amount = x.amt_mean >= self.thresholds['min_amount']
            has_investment_variability = x.amt_cv >= self.thresholds['min_cv']  # Not too regular
            not_too_variable = x.amt_cv <= self.thresholds['max_cv']  # But not chaotic

            if has_reasonable_amount and has_investment_variability and not_too_variable:
                return self.POSITIVE

            return self.ABSTAIN

        def lf_not_investment_savings_like(x):
            """Negative LF: Very regular, small amounts are likely savings"""
            if x.amt_mean <= 0:
                return self.ABSTAIN

            # Small, very regular amounts with low variability = likely savings
            is_small = x.amt_mean < 50
            is_very_regular = (
                (28 <= x.mean_delta_days <= 32) or  # Monthly
                (88 <= x.mean_delta_days <= 95)     # Quarterly
            )
            is_very_consistent = x.amt_cv <= 0.2

            if is_small and is_very_regular and is_very_consistent:
                return self.NEGATIVE

            return self.ABSTAIN
        def lf_investment_naf_codes(x):
            """NAF codes for investment management, brokerage, and fund companies"""
            if pd.isna(x.NAF_CODE):
                return self.ABSTAIN

            # NAF codes for investment services, fund management, brokerage
            investment_naf_codes = [
                "66.12", "66.12Z",          # Security and commodity contracts brokerage
                "66.19", "66.19Z",          # Other activities auxiliary to financial services
                "66.30", "66.30Z",          # Fund management activities
                "64.91", "64.91Z",          # Financial leasing
                "64.99", "64.99Z",          # Other financial service activities (investment-related)
                "70.10", "70.10Z",          # Activities of head offices (holding companies)
                "70.22", "70.22Z",          # Business and other management consultancy activities
                "82.99", "82.99Z",          # Other business support service activities
                "68.10", "68.10Z",          # Buying and selling of own real estate (REITs)
                "68.20", "68.20Z",          # Renting and operating of own or leased real estate
                "77.40", "77.40Z",          # Leasing of intellectual property (IP investments)
                "01.61Z", "01.62Z",         # Support activities for crop production (agricultural funds)
                "46.15Z",                   # Agents involved in the sale of furniture and other goods
                "77.11Z",                   # Rental of cars and light motor vehicles (vehicle funds)
            ]

            if str(x.NAF_CODE).strip() in investment_naf_codes:
                if x.amt_mean >= self.thresholds['min_amount']:
                    return self.POSITIVE
            return self.ABSTAIN

        def lf_investment_broker_merchants(x):
            """Known investment brokers, fund companies, and investment platforms"""
            if pd.isna(x.MERCHANT):
                return self.ABSTAIN

            merchant_text = str(x.MERCHANT).strip()

            # Investment brokers, fund companies, and platforms
            investment_merchants = [
                # Major brokers/platforms
                "Degiro", "Interactive Brokers", "Saxo Bank", "eToro", "Plus500",
                "Trading 212", "Freetrade", "Robinhood", "E*TRADE", "TD Ameritrade",
                "Charles Schwab", "Fidelity", "Vanguard", "Merrill Lynch", "Morgan Stanley",
                "Goldman Sachs", "J.P. Morgan", "UBS", "Credit Suisse", "Deutsche Bank Securities",

                # French brokers/banks with securities services
                "Boursorama Securities", "Fortuneo Securities", "BNP Paribas Securities",
                "Crédit Agricole Titres", "Société Générale Securities", "Binck Bank",
                "Bourse Direct", "Lynx Broker", "IG Markets", "CMC Markets",

                # Fund management companies
                "BlackRock", "Vanguard Group", "State Street", "Fidelity Investments",
                "Capital Group", "T. Rowe Price", "Franklin Templeton", "Invesco",
                "Amundi", "AXA Investment Managers", "BNP Paribas Asset Management",
                "Natixis Investment Managers", "Carmignac", "Lazard Asset Management",

                # European investment firms
                "Lyxor Asset Management", "BNPP AM", "CPR Asset Management",
                "Ostrum Asset Management", "Edmond de Rothschild Asset Management",
                "La Française Asset Management", "Tikehau Investment Management",

                # Robo-advisors and digital investment platforms
                "Betterment", "Wealthfront", "Acorns", "Stash", "M1 Finance",
                "Wealthsimple", "Nutmeg", "Moneyfarm", "Scalable Capital", "Trade Republic",
                "Yomoni", "Nalo", "WeSave", "Advize", "Linxea",

                # Alternative investment platforms
                "YieldStreet", "Fundrise", "RealtyMogul", "CrowdStreet", "EquityMultiple",
                "AngelList", "SeedInvest", "StartEngine", "Republic", "Crowdcube",

                # Crypto/digital asset platforms (that may distribute gains)
                "Coinbase", "Binance", "Kraken", "Bitpanda", "Bitstamp", "Gemini",
                "BlockFi", "Celsius", "Nexo", "Crypto.com", "Paymium", "Bitit"
            ]

            # Check for exact match first
            if merchant_text in investment_merchants:
                if x.amt_mean >= self.thresholds['min_amount']:
                    return self.POSITIVE

            # Check for partial matches (case-insensitive)
            merchant_lower = merchant_text.lower()
            for broker in investment_merchants:
                if broker.lower() in merchant_lower or merchant_lower in broker.lower():
                    if x.amt_mean >= self.thresholds['min_amount']:
                        return self.POSITIVE

            return self.ABSTAIN

        # Include other investment LFs from previous version...
        # (quarterly patterns, broker detection, etc.)

        return [
            LabelingFunction(name="lf_investment_explicit_terms", f=lf_investment_explicit_terms),
            LabelingFunction(name="lf_investment_variable_amounts", f=lf_investment_variable_amounts),
            LabelingFunction(name="lf_investment_naf_codes", f=lf_investment_naf_codes),
            LabelingFunction(name="lf_investment_broker_merchants", f=lf_investment_broker_merchants),
            LabelingFunction(name="lf_not_investment_savings_like", f=lf_not_investment_savings_like),
            # Add other LFs...
        ]


# Usage Example
def create_comprehensive_income_classifiers(ft_model, merchant_agg_df, user_profile=None):
    """Create both savings and investment classifiers"""

    # Create savings classifier
    savings_classifier = SavingsIncomeClassifier(ft_model, merchant_agg_df.copy(), user_profile)
    savings_results = savings_classifier.run_full_pipeline(confidence_threshold=0.8)

    # Create investment classifier
    investment_classifier = InvestmentIncomeClassifier(ft_model, merchant_agg_df.copy(), user_profile)
    investment_results = investment_classifier.run_full_pipeline(confidence_threshold=0.7)

    return {
        'savings': {'classifier': savings_classifier, 'results': savings_results},
        'investment': {'classifier': investment_classifier, 'results': investment_results}
    }

# Example usage:
"""
classifiers = create_comprehensive_income_classifiers(ft, merchant_agg_df, user_profile)

print("Savings Income:", classifiers['savings']['results']['predicted_positive'])
print("Investment Income:", classifiers['investment']['results']['predicted_positive'])

# Access dataframes with predictions
savings_df = classifiers['savings']['classifier'].df
investment_df = classifiers['investment']['classifier'].df
"""

# =============================================================================
# OPTION 1: Run Classifiers Separately
# =============================================================================

# 1A. Savings Income Classifier
print("=== SAVINGS INCOME CLASSIFICATION ===")
savings_classifier = SavingsIncomeClassifier(ft, merchant_agg_df, user_profile)
savings_results = savings_classifier.run_full_pipeline(confidence_threshold=0.8)

# Export savings LF results to Excel
savings_results_df = extract_lf_results_to_excel(
    savings_classifier,
    merchant_agg_df,
    "savings_lf_detailed_results.xlsx"
)

print(f"Savings Income Results:")
print(f"- Total predicted: {savings_results['predicted_positive']}")
print(f"- High confidence: {savings_results['high_confidence_positive']}")

# 1B. Investment Income Classifier
print("\n=== INVESTMENT INCOME CLASSIFICATION ===")
investment_classifier = InvestmentIncomeClassifier(ft, merchant_agg_df, user_profile)
investment_results = investment_classifier.run_full_pipeline(confidence_threshold=0.6)

# Export investment LF results to Excel
investment_results_df = extract_lf_results_to_excel(
    investment_classifier,
    merchant_agg_df,
    "investment_lf_detailed_results.xlsx"
)

print(f"Investment Income Results:")
print(f"- Total predicted: {investment_results['predicted_positive']}")
print(f"- High confidence: {investment_results['high_confidence_positive']}")

"""# Exceptionnal income

- Variable
- Other

"""

"""
Exceptional Income Classifier - Handles irregular, one-time, or infrequent income
This includes bonuses, winnings, inheritance, gifts, refunds, legal settlements, etc.
"""

import pandas as pd
import numpy as np
import re
from snorkel.labeling import LabelingFunction
from typing import List

class ExceptionalIncomeClassifier(CategoryClassifier):
    """Exceptional income classifier for irregular, one-time, or infrequent income"""

    def __init__(self, ft_model, dataframe: pd.DataFrame, user_profile=None):
        super().__init__("Exceptional", ft_model, dataframe)
        self.user_profile = user_profile
        self.thresholds = self._calculate_exceptional_thresholds()

        # Exceptional income anchor words
        self.exceptional_anchor_terms = [
            "bonus", "prime", "gift", "cadeau", "remboursement", "refund",
            "win", "gain", "lot", "heritage", "inheritance", "settlement"
        ]

        # Exceptional income terms organized by category
        self.exceptional_terms = {
            # Bonuses and rewards
            "bonuses": ["bonus", "prime", "primes", "gratification", "reward",
                       "récompense", "incentive", "commission", "commissions"],

            # Winnings and gambling
            "winnings": ["gain", "gains", "win", "wins", "lot", "lots", "lottery",
                        "loterie", "casino", "bet", "paris", "pari", "jackpot",
                        "prize", "prix", "concours", "contest", "sweepstake"],

            # Gifts and inheritance
            "gifts": ["gift", "gifts", "cadeau", "cadeaux", "don", "dons", "donation",
                     "heritage", "héritage", "inheritance", "legacy", "succession",
                     "testament", "will"],

            # Refunds and reimbursements
            "refunds": ["refund", "refunds", "remboursement", "remboursements",
                       "rembourse", "restitution", "credit", "crédit", "avoir",
                       "retour", "return", "chargeback"],

            # Legal and insurance settlements
            "settlements": ["settlement", "settlements", "indemnité", "indemnités",
                           "indemnisation", "compensation", "dommages", "damages",
                           "assurance", "insurance", "sinistre", "claim"],

            # Government payments (one-time)
            "government": ["allocation", "allocations", "aide", "aides", "subvention",
                          "grant", "grants", "subsidy", "subsidies", "tax credit",
                          "crédit impot", "stimulus", "covid", "pandemic"],

            # Sale proceeds (one-time)
            "sales": ["vente", "sale", "proceeds", "produit", "cession", "disposal",
                     "liquidation", "sold", "vendu"],

            # Freelance/consulting (irregular)
            "freelance": ["freelance", "consulting", "consultant", "prestation",
                         "honoraires", "fees", "project", "projet", "mission",
                         "contract", "contrat", "gig"],

            # Royalties and licensing
            "royalties": ["royalty", "royalties", "redevance", "redevances",
                         "licence", "license", "copyright", "patent", "brevet",
                         "intellectual property", "propriété intellectuelle"]
        }

        # Flatten terms
        self.all_exceptional_terms = []
        for category_terms in self.exceptional_terms.values():
            self.all_exceptional_terms.extend(category_terms)

        # Setup FastText anchors
        self.setup_anchors(self.exceptional_anchor_terms, similarity_threshold=0.65)

    def _calculate_exceptional_thresholds(self) -> dict:
        """Calculate thresholds for exceptional income detection"""
        base_thresholds = {
            'min_amount': 50,           # Higher minimum (exceptional should be meaningful)
            'max_amount': 1000000,      # Very high ceiling (inheritance, lottery, etc.)
            'large_amount': 1000,       # Threshold for "large" exceptional income
            'very_large_amount': 10000, # Threshold for "very large" exceptional income
            'max_frequency': 6,         # Maximum transactions per year to be "exceptional"
            'max_cv': 5.0,             # Very high CV tolerance (highly irregular)
            'min_days_between': 60,     # Minimum days between transactions to be irregular
        }

        # Adjust based on user's income level
        if self.user_profile and hasattr(self.user_profile, 'monthly_income_range'):
            if self.user_profile.monthly_income_range == "4000_plus":
                base_thresholds.update({
                    'min_amount': 200,          # Higher minimum for wealthy users
                    'large_amount': 2000,
                    'very_large_amount': 20000
                })
            elif self.user_profile.monthly_income_range == "under_1500":
                base_thresholds.update({
                    'min_amount': 25,           # Lower minimum for lower income
                    'large_amount': 500,
                    'very_large_amount': 5000
                })

        return base_thresholds

    def create_labeling_functions(self) -> List[LabelingFunction]:
        """Create exceptional income-specific labeling functions"""

        def lf_exceptional_explicit_terms(x):
            """Detect exceptional income based on explicit terms"""
            if pd.isna(x.CLEANED_TEXT) or x.CLEANED_TEXT == "":
                return self.ABSTAIN

            text_lower = x.CLEANED_TEXT.lower()

            # Check for explicit exceptional income terms
            for term in self.all_exceptional_terms:
                if re.search(rf"\b{re.escape(term)}\b", text_lower):
                    if x.amt_mean >= self.thresholds['min_amount']:
                        return self.POSITIVE

            return self.ABSTAIN

        def lf_exceptional_fasttext_similarity(x):
            """Detect exceptional income using FastText similarity"""
            if not self.anchor_system or pd.isna(x.CLEANED_TEXT) or x.CLEANED_TEXT == "":
                return self.ABSTAIN

            similarity = self.anchor_system.get_text_similarity(x.CLEANED_TEXT)

            # Higher similarity threshold for exceptional income
            if similarity >= 0.7 and x.amt_mean >= self.thresholds['min_amount']:
                return self.POSITIVE

            return self.ABSTAIN

        def lf_exceptional_large_infrequent(x):
            """Detect large, infrequent amounts (classic exceptional pattern)"""
            if x.amt_mean <= 0:
                return self.ABSTAIN

            # Large amounts that occur infrequently
            is_large = x.amt_mean >= self.thresholds['large_amount']
            is_infrequent = x.amt_count <= self.thresholds['max_frequency']
            has_gaps = x.mean_delta_days >= self.thresholds['min_days_between'] if x.amt_count > 1 else True

            if is_large and is_infrequent and has_gaps:
                return self.POSITIVE

            return self.ABSTAIN

        def lf_exceptional_very_large_single(x):
            """Detect very large single payments (inheritance, lottery, etc.)"""
            if x.amt_count == 1 and x.amt_mean >= self.thresholds['very_large_amount']:
                return self.POSITIVE
            return self.ABSTAIN

        def lf_exceptional_bonus_timing(x):
            """Detect bonus-like timing patterns (end of year, quarterly)"""
            if x.amt_mean <= 0 or x.amt_count < 2:
                return self.ABSTAIN

            # Bonus patterns: annual (~365 days) or quarterly (~90 days) but irregular amounts
            is_annual_bonus = 350 <= x.mean_delta_days <= 380
            is_quarterly_bonus = 85 <= x.mean_delta_days <= 100

            # Bonuses often vary in amount (performance-based)
            has_variability = x.amt_cv >= 0.3
            is_meaningful_amount = x.amt_mean >= self.thresholds['min_amount']

            if (is_annual_bonus or is_quarterly_bonus) and has_variability and is_meaningful_amount:
                return self.POSITIVE

            return self.ABSTAIN

        def lf_exceptional_naf_codes(x):
            """NAF codes associated with exceptional income sources"""
            if pd.isna(x.NAF_CODE):
                return self.ABSTAIN

            # NAF codes for activities that might generate exceptional income
            exceptional_naf_codes = [
                "92.00Z",  # Gambling and betting activities
                "93.11Z",  # Operation of sports facilities
                "93.12Z",  # Activities of sport clubs
                "93.13Z",  # Fitness facilities
                "93.19Z",  # Other sports activities
                "90.01Z",  # Performing arts
                "90.02Z",  # Support activities to performing arts
                "90.03A",  # Artistic creation
                "90.03B",  # Other artistic creation
                "90.04Z",  # Operation of arts facilities
                "58.11Z",  # Book publishing
                "58.13Z",  # Publishing of newspapers
                "58.14Z",  # Publishing of journals and periodicals
                "59.11A",  # Motion picture production
                "59.11B",  # Motion picture post-production
                "59.11C",  # Motion picture distribution
                "59.13A",  # Distribution of motion pictures
                "59.13B",  # Edition and distribution of video recordings
                "59.14Z",  # Motion picture projection activities
                "60.10Z",  # Radio broadcasting
                "60.20A",  # Television programming and broadcasting
                "60.20B",  # Television programming and broadcasting
                "77.21Z",  # Renting and leasing of recreational goods
                "77.22Z",  # Renting of video tapes and disks
                "77.29Z",  # Renting and leasing of other consumer goods
                "68.31Z",  # Real estate agencies
                "68.32A",  # Administration of residential real estate
                "68.32B",  # Administration of non-residential real estate
                "77.40Z",  # Leasing of intellectual property
                "82.30Z",  # Organisation of conventions and trade shows
                "82.99Z",  # Other business support service activities
                "84.13Z",  # Regulation of and contribution to more efficient operation
                "88.99A",  # Other social work activities without accommodation n.e.c.
                "88.99B",  # Other social work activities without accommodation n.e.c.
                "94.12Z",  # Activities of professional membership organisations
                "94.99Z",  # Activities of other membership organisations n.e.c.
                "96.09Z"   # Other personal service activities n.e.c.
            ]

            if str(x.NAF_CODE).strip() in exceptional_naf_codes:
                if x.amt_mean >= self.thresholds['min_amount']:
                    return self.POSITIVE
            return self.ABSTAIN

        def lf_exceptional_merchants(x):
            """Known merchants/sources of exceptional income"""
            if pd.isna(x.MERCHANT):
                return self.ABSTAIN

            merchant_text = str(x.MERCHANT).strip()

            # Merchants associated with exceptional income
            exceptional_merchants = [
                # Lottery and gambling
                "Française des Jeux", "FDJ", "PMU", "Betclic", "Winamax", "PokerStars",
                "Unibet", "Bet365", "William Hill", "Ladbrokes", "Paddy Power",
                "DraftKings", "FanDuel", "BetMGM", "Caesars", "MGM", "Harrah's",

                # Government agencies (tax refunds, stimulus)
                "Trésor Public", "Direction Générale des Finances Publiques", "DGFIP",
                "IRS", "Internal Revenue Service", "HM Revenue", "HMRC", "CRA",
                "Canada Revenue Agency", "Centrelink", "Social Security Administration",

                # Insurance companies (settlements)
                "AXA", "Allianz", "Generali", "Aviva", "Zurich", "Swiss Re",
                "Munich Re", "State Farm", "Geico", "Progressive", "Allstate",
                "Farmers Insurance", "Liberty Mutual", "Travelers", "Chubb",

                # Legal/settlement services
                "PayPal Resolution", "Escrow", "Settlement Fund", "Class Action",
                "Legal Settlement", "Court Settlement", "Arbitration",

                # Auction houses and collectibles
                "Sotheby's", "Christie's", "Phillips", "Heritage Auctions",
                "eBay", "Catawiki", "Drouot", "Artcurial",

                # Royalty collection societies
                "SACEM", "ASCAP", "BMI", "SESAC", "PRS", "GEMA", "STIM",

                # Crowdfunding platforms
                "Kickstarter", "Indiegogo", "GoFundMe", "Patreon", "Tipeee",
                "Ulule", "KissKissBankBank", "Leetchi",

                # Patent/IP licensing
                "Patent Licensing", "IP Royalty", "Trademark Licensing",
                "Copyright Collective", "Licensing Corporation"
            ]

            # Check for exact match first
            if merchant_text in exceptional_merchants:
                if x.amt_mean >= self.thresholds['min_amount']:
                    return self.POSITIVE

            # Check for partial matches (case-insensitive)
            merchant_lower = merchant_text.lower()
            for merchant in exceptional_merchants:
                if merchant.lower() in merchant_lower or merchant_lower in merchant.lower():
                    if x.amt_mean >= self.thresholds['min_amount']:
                        return self.POSITIVE

            return self.ABSTAIN

        def lf_exceptional_high_variability(x):
            """Detect income with very high variability (irregular amounts)"""
            if x.amt_mean <= 0 or x.amt_count < 3:
                return self.ABSTAIN

            # Very high coefficient of variation suggests irregular/exceptional income
            has_high_variability = x.amt_cv >= 2.0
            is_meaningful_amount = x.amt_mean >= self.thresholds['min_amount']
            is_infrequent = x.amt_count <= self.thresholds['max_frequency']

            if has_high_variability and is_meaningful_amount and is_infrequent:
                return self.POSITIVE

            return self.ABSTAIN

        def lf_not_exceptional_regular_salary(x):
            """Negative LF: Regular salary-like patterns are not exceptional"""
            if x.amt_mean <= 0:
                return self.ABSTAIN

            # Very regular patterns are likely salary, not exceptional
            is_very_regular = (
                (26 <= x.mean_delta_days <= 32) or  # Monthly
                (13 <= x.mean_delta_days <= 16) or  # Bi-weekly
                (6 <= x.mean_delta_days <= 8)       # Weekly
            )

            is_consistent = x.amt_cv < 0.2
            is_frequent = x.amt_count > 6  # More than 6 times suggests regular income

            if is_very_regular and is_consistent and is_frequent:
                return self.NEGATIVE

            return self.ABSTAIN

        def lf_not_exceptional_small_regular(x):
            """Negative LF: Small, regular amounts are not exceptional"""
            if x.amt_mean < 20 and x.amt_count > 4 and x.amt_cv < 0.5:
                return self.NEGATIVE
            return self.ABSTAIN

        return [
            LabelingFunction(name="lf_exceptional_explicit_terms", f=lf_exceptional_explicit_terms),
            LabelingFunction(name="lf_exceptional_fasttext_similarity", f=lf_exceptional_fasttext_similarity),
            LabelingFunction(name="lf_exceptional_large_infrequent", f=lf_exceptional_large_infrequent),
            LabelingFunction(name="lf_exceptional_very_large_single", f=lf_exceptional_very_large_single),
            LabelingFunction(name="lf_exceptional_bonus_timing", f=lf_exceptional_bonus_timing),
            LabelingFunction(name="lf_exceptional_naf_codes", f=lf_exceptional_naf_codes),
            LabelingFunction(name="lf_exceptional_merchants", f=lf_exceptional_merchants),
            LabelingFunction(name="lf_exceptional_high_variability", f=lf_exceptional_high_variability),
            LabelingFunction(name="lf_not_exceptional_regular_salary", f=lf_not_exceptional_regular_salary),
            LabelingFunction(name="lf_not_exceptional_small_regular", f=lf_not_exceptional_small_regular),
        ]


# Usage example
def create_exceptional_classifier(ft_model, merchant_agg_df, user_profile=None):
    """Create and run exceptional income classifier"""

    # Create classifier instance
    classifier = ExceptionalIncomeClassifier(ft_model, merchant_agg_df, user_profile)

    # Run full pipeline
    results = classifier.run_full_pipeline(confidence_threshold=0.7)

    return classifier, results


# Example usage:
"""
exceptional_classifier, results = create_exceptional_classifier(
    ft_model=ft,
    merchant_agg_df=merchant_agg_df,
    user_profile=user_profile
)

print(f"Exceptional income transactions: {results['predicted_positive']}")
print(f"High confidence: {results['high_confidence_positive']}")

# Export results
exceptional_excel = extract_lf_results_to_excel(
    exceptional_classifier, merchant_agg_df, "exceptional_lf_detailed_results.xlsx"
)
"""